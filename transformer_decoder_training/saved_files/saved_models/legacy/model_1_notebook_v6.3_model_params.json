{"num_emb": 24, "num_output_dim": 12, "hidden_size": 256, "num_layers": 8, "num_heads": 8, "training_params": {"learning_rate": 0.001, "num_epochs": 20, "optimizer": "Adam", "loss_fn": "BCEWithLogitsLoss"}, "training_data_params": {"sos_token": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], "pad_token": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]], "snapshot_intervall": 0.05, "batch_size": 64, "sequence_length": 512, "stride": 256}}