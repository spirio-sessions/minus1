{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-08T21:56:13.147075Z",
     "start_time": "2024-09-08T21:54:48.265803Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import data_visualization.Visualization as visualization\n",
    "import json\n",
    "from pathlib import Path\n",
    "import transformer_decoder_training.testing_helper_functions as test_helpers\n",
    "\n",
    "projects_dir = \"/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models\"\n",
    "test_data_dir = \"/home/falaxdb/Repos/minus1/transformer_decoder_training/test_files_and_configs/legacy\"\n",
    "test_configs_dir = \"/home/falaxdb/Repos/minus1/transformer_decoder_training/test_files_and_configs/test_config_02_only\"\n",
    "\n",
    "\n",
    "# Check if GPU is available, set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = test_helpers.load_transformer_model(\"/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.6\", projects_dir, device, load_best_checkpoint=True)\n",
    "\n",
    "test_helpers.testinference_for_model(model, \"transformer_1.6\", projects_dir, device, \"/home/falaxdb/Repos/minus1/transformer_decoder_training/test_files_and_configs/split_into_midis\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch is epoch number 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing configurations:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      "                                            \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The song simple_test does already exist for the configuration /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.6/tests/threshold_02/simple_test_configuration.json, skipping\n",
      "The song short_cord_progression does already exist for the configuration /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.6/tests/threshold_02/short_cord_progression_configuration.json, skipping\n",
      "The song moritz_maria does already exist for the configuration /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.6/tests/threshold_02/moritz_maria_configuration.json, skipping\n",
      "The song raindrop_prelude does already exist for the configuration /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.6/tests/threshold_02/raindrop_prelude_configuration.json, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 2048, 24])\n",
      "Tokens to generate: 2048\n",
      "Elapsed time: 29.3541 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2048, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2048, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:29<01:29, 29.68s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.6/tests/threshold_005/simple_test.mid\n",
      "sequecne tensor: torch.Size([1280, 24])\n",
      "sequence with start token tensor: torch.Size([1281, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 768, 24])\n",
      "Tokens to generate: 768\n",
      "Elapsed time: 11.1959 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([768, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 768, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1281, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.6/tests/threshold_005/short_cord_progression.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Songs:  50%|█████     | 2/4 [00:41<00:37, 18.93s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([1361, 24])\n",
      "sequence with start token tensor: torch.Size([1362, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 849, 24])\n",
      "Tokens to generate: 849\n",
      "Elapsed time: 12.2948 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([849, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 849, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1362, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.6/tests/threshold_005/moritz_maria.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:53<00:15, 16.00s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2480, 24])\n",
      "sequence with start token tensor: torch.Size([2481, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 1968, 24])\n",
      "Tokens to generate: 1968\n",
      "Elapsed time: 28.4750 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1968, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1968, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2481, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Songs: 100%|██████████| 4/4 [01:22<00:00, 21.05s/it]\u001B[A\n",
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.6/tests/threshold_005/raindrop_prelude.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
