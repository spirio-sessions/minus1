{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-03T00:51:16.244504Z",
     "start_time": "2024-09-03T00:51:15.133375Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import data_visualization.Visualization as visualization\n",
    "import json\n",
    "from pathlib import Path\n",
    "import transformer_decoder_training.testing_helper_functions as test_helpers\n",
    "\n",
    "# Check if GPU is available, set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T00:51:16.247220Z",
     "start_time": "2024-09-03T00:51:16.245385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "projects_dir = \"/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models\"\n",
    "test_data_dir = \"/home/falaxdb/Repos/minus1/transformer_decoder_training/test_files_and_configs/split_into_midis\"\n",
    "test_configs_dir = \"/home/falaxdb/Repos/minus1/transformer_decoder_training/test_files_and_configs/test_config_02_only\""
   ],
   "id": "db4b595478180a27",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T00:51:16.262717Z",
     "start_time": "2024-09-03T00:51:16.247788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create test configurations\n",
    "# config = test_helpers.create_json_testing_template()\n",
    "# \n",
    "# config[\"test_row_name\"] = \"top_k\"\n",
    "# config[\"threshold\"] = None\n",
    "# config[\"inference_method\"] = \"inference_top_k_truth_notes\"\n",
    "# \n",
    "# test_helpers.save_json_testing_configuration(config, test_configs_dir, overwrite=False)"
   ],
   "id": "305c0a45ac82150d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T00:51:16.272730Z",
     "start_time": "2024-09-03T00:51:16.264128Z"
    }
   },
   "cell_type": "code",
   "source": "test_helpers.copy_testing_templates_to_all_models(projects_dir, test_configs_dir, override=False)",
   "id": "2279f8fc1cca1f4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 projects\n",
      "Found 1 config files\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_01 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.2 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.3 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.4 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.5 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.2 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.0 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.1 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.3 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.4 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.5 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.6 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.7 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_2.0 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.9 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_3.0 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_3.1 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.10 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.8 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.11 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_3.2 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.12 already has a test directory and override is False, skipping\n",
      "/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.11_overfitted already has a test directory and override is False, skipping\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T01:07:42.379614Z",
     "start_time": "2024-09-03T00:51:16.274491Z"
    }
   },
   "cell_type": "code",
   "source": "test_helpers.testinference_for_all_models(projects_dir, test_data_dir, device)",
   "id": "43925c294eb457ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 projects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projects:   0%|          | 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Testing model transformer_01\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_01\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 17, 24])\n",
      "continuing seq torch.Size([1, 2544, 24])\n",
      "Tokens to generate: 2544\n",
      "Elapsed time: 3.2288 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2544, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2544, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:03<00:10,  3.53s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_01/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([1280, 24])\n",
      "sequence with start token tensor: torch.Size([1281, 24])\n",
      "context_seq tensor: torch.Size([1, 17, 24])\n",
      "continuing seq torch.Size([1, 1264, 24])\n",
      "Tokens to generate: 1264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:05<00:04,  2.44s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.5275 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1264, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1264, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1281, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_01/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([1361, 24])\n",
      "sequence with start token tensor: torch.Size([1362, 24])\n",
      "context_seq tensor: torch.Size([1, 17, 24])\n",
      "continuing seq torch.Size([1, 1345, 24])\n",
      "Tokens to generate: 1345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:06<00:02,  2.12s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.6181 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1345, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1345, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1362, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_01/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([2480, 24])\n",
      "sequence with start token tensor: torch.Size([2481, 24])\n",
      "context_seq tensor: torch.Size([1, 17, 24])\n",
      "continuing seq torch.Size([1, 2464, 24])\n",
      "Tokens to generate: 2464\n",
      "Elapsed time: 2.9348 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2464, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2464, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2481, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_01/tests/threshold_02/raindrop_prelude.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [00:10<00:00,  2.54s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [00:10<00:00, 10.14s/it]\u001B[A\n",
      "Projects:   4%|▍         | 1/23 [00:10<03:54, 10.66s/it]             \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Testing model transformer_0.2\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.2\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 101, 24])\n",
      "continuing seq torch.Size([1, 2460, 24])\n",
      "Tokens to generate: 2460\n",
      "Elapsed time: 2.9914 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2460, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2460, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:03<00:09,  3.29s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.2/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([1280, 24])\n",
      "sequence with start token tensor: torch.Size([1281, 24])\n",
      "context_seq tensor: torch.Size([1, 101, 24])\n",
      "continuing seq torch.Size([1, 1180, 24])\n",
      "Tokens to generate: 1180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:04<00:04,  2.30s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.4734 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1180, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1180, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1281, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.2/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([1361, 24])\n",
      "sequence with start token tensor: torch.Size([1362, 24])\n",
      "context_seq tensor: torch.Size([1, 101, 24])\n",
      "continuing seq torch.Size([1, 1261, 24])\n",
      "Tokens to generate: 1261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:06<00:02,  2.02s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.5314 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1261, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1261, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1362, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.2/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([2480, 24])\n",
      "sequence with start token tensor: torch.Size([2481, 24])\n",
      "context_seq tensor: torch.Size([1, 101, 24])\n",
      "continuing seq torch.Size([1, 2380, 24])\n",
      "Tokens to generate: 2380\n",
      "Elapsed time: 2.8979 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2380, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2380, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2481, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [00:09<00:00,  2.47s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [00:09<00:00,  9.75s/it]\u001B[A\n",
      "Projects:   9%|▊         | 2/23 [00:20<03:36, 10.31s/it]             \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.2/tests/threshold_02/raindrop_prelude.mid\n",
      "\n",
      "==============================\n",
      "Testing model transformer_0.3\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.3\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 2048, 24])\n",
      "Tokens to generate: 2048\n",
      "Elapsed time: 9.5911 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2048, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2048, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:09<00:29,  9.94s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.3/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([1280, 24])\n",
      "sequence with start token tensor: torch.Size([1281, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 768, 24])\n",
      "Tokens to generate: 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:13<00:12,  6.32s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3.6168 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([768, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 768, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1281, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.3/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([1361, 24])\n",
      "sequence with start token tensor: torch.Size([1362, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 849, 24])\n",
      "Tokens to generate: 849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:17<00:05,  5.35s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 4.0332 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([849, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 849, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1362, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.3/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([2480, 24])\n",
      "sequence with start token tensor: torch.Size([2481, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 1968, 24])\n",
      "Tokens to generate: 1968\n",
      "Elapsed time: 9.2986 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1968, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1968, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2481, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [00:27<00:00,  7.02s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [00:27<00:00, 27.51s/it]\u001B[A\n",
      "Projects:  13%|█▎        | 3/23 [00:49<06:11, 18.57s/it]             \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.3/tests/threshold_02/raindrop_prelude.mid\n",
      "\n",
      "==============================\n",
      "Testing model transformer_0.4\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.4\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 9, 24])\n",
      "continuing seq torch.Size([1, 2552, 24])\n",
      "Tokens to generate: 2552\n",
      "Elapsed time: 3.1289 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2552, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2552, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:03<00:10,  3.44s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.4/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([1280, 24])\n",
      "sequence with start token tensor: torch.Size([1281, 24])\n",
      "context_seq tensor: torch.Size([1, 9, 24])\n",
      "continuing seq torch.Size([1, 1272, 24])\n",
      "Tokens to generate: 1272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:05<00:04,  2.41s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.5618 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1272, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1272, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1281, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.4/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([1361, 24])\n",
      "sequence with start token tensor: torch.Size([1362, 24])\n",
      "context_seq tensor: torch.Size([1, 9, 24])\n",
      "continuing seq torch.Size([1, 1353, 24])\n",
      "Tokens to generate: 1353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:07<00:02,  2.17s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.7533 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1353, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1353, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1362, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.4/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([2480, 24])\n",
      "sequence with start token tensor: torch.Size([2481, 24])\n",
      "context_seq tensor: torch.Size([1, 9, 24])\n",
      "continuing seq torch.Size([1, 2472, 24])\n",
      "Tokens to generate: 2472\n",
      "Elapsed time: 2.9964 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2472, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2472, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2481, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.4/tests/threshold_02/raindrop_prelude.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [00:10<00:00,  2.60s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [00:10<00:00, 10.27s/it]\u001B[A\n",
      "Projects:  17%|█▋        | 4/23 [01:00<04:56, 15.59s/it]             \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Testing model transformer_0.5\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.5\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 5, 24])\n",
      "continuing seq torch.Size([1, 2556, 24])\n",
      "Tokens to generate: 2556\n",
      "Elapsed time: 3.1334 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2556, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2556, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.5/tests/threshold_02/simple_test.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:03<00:10,  3.38s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([1280, 24])\n",
      "sequence with start token tensor: torch.Size([1281, 24])\n",
      "context_seq tensor: torch.Size([1, 5, 24])\n",
      "continuing seq torch.Size([1, 1276, 24])\n",
      "Tokens to generate: 1276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:05<00:04,  2.42s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.6082 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1276, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1276, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1281, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.5/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([1361, 24])\n",
      "sequence with start token tensor: torch.Size([1362, 24])\n",
      "context_seq tensor: torch.Size([1, 5, 24])\n",
      "continuing seq torch.Size([1, 1357, 24])\n",
      "Tokens to generate: 1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:06<00:02,  2.13s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.6520 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1357, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1357, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1362, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.5/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([2480, 24])\n",
      "sequence with start token tensor: torch.Size([2481, 24])\n",
      "context_seq tensor: torch.Size([1, 5, 24])\n",
      "continuing seq torch.Size([1, 2476, 24])\n",
      "Tokens to generate: 2476\n",
      "Elapsed time: 2.9923 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2476, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2476, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2481, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_0.5/tests/threshold_02/raindrop_prelude.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [00:10<00:00,  2.57s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [00:10<00:00, 10.16s/it]\u001B[A\n",
      "Projects:  22%|██▏       | 5/23 [01:11<04:10, 13.91s/it]             \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Testing model transformer_1.2\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.2\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 5, 24])\n",
      "continuing seq torch.Size([1, 2556, 24])\n",
      "Tokens to generate: 2556\n",
      "Elapsed time: 3.1133 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2556, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2556, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.2/tests/threshold_02/simple_test.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:03<00:10,  3.37s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([1280, 24])\n",
      "sequence with start token tensor: torch.Size([1281, 24])\n",
      "context_seq tensor: torch.Size([1, 5, 24])\n",
      "continuing seq torch.Size([1, 1276, 24])\n",
      "Tokens to generate: 1276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:05<00:04,  2.38s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.5579 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1276, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1276, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1281, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.2/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([1361, 24])\n",
      "sequence with start token tensor: torch.Size([1362, 24])\n",
      "context_seq tensor: torch.Size([1, 5, 24])\n",
      "continuing seq torch.Size([1, 1357, 24])\n",
      "Tokens to generate: 1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:06<00:02,  2.11s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.6454 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1357, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1357, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1362, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.2/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([2480, 24])\n",
      "sequence with start token tensor: torch.Size([2481, 24])\n",
      "context_seq tensor: torch.Size([1, 5, 24])\n",
      "continuing seq torch.Size([1, 2476, 24])\n",
      "Tokens to generate: 2476\n",
      "Elapsed time: 2.9819 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2476, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2476, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2481, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.2/tests/threshold_02/raindrop_prelude.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [00:10<00:00,  2.55s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [00:10<00:00, 10.07s/it]\u001B[A\n",
      "Projects:  26%|██▌       | 6/23 [01:21<03:38, 12.87s/it]             \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Testing model transformer_1.0\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.0\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 2048, 24])\n",
      "Tokens to generate: 2048\n",
      "Elapsed time: 9.4535 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2048, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2048, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:09<00:29,  9.74s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.0/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([1280, 24])\n",
      "sequence with start token tensor: torch.Size([1281, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 768, 24])\n",
      "Tokens to generate: 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:13<00:12,  6.25s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3.6303 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([768, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 768, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1281, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.0/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([1361, 24])\n",
      "sequence with start token tensor: torch.Size([1362, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 849, 24])\n",
      "Tokens to generate: 849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:17<00:05,  5.32s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 4.0429 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([849, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 849, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1362, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.0/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([2480, 24])\n",
      "sequence with start token tensor: torch.Size([2481, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 1968, 24])\n",
      "Tokens to generate: 1968\n",
      "Elapsed time: 9.1963 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1968, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1968, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2481, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [00:27<00:00,  6.96s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [00:27<00:00, 27.23s/it]\u001B[A\n",
      "Projects:  30%|███       | 7/23 [01:49<04:45, 17.83s/it]             \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.0/tests/threshold_02/raindrop_prelude.mid\n",
      "\n",
      "==============================\n",
      "Testing model transformer_1.1\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.1\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 1025, 24])\n",
      "continuing seq torch.Size([1, 1536, 24])\n",
      "Tokens to generate: 1536\n",
      "Elapsed time: 14.8935 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1536, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1536, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:15<00:45, 15.21s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.1/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([1280, 24])\n",
      "sequence with start token tensor: torch.Size([1281, 24])\n",
      "context_seq tensor: torch.Size([1, 1025, 24])\n",
      "continuing seq torch.Size([1, 256, 24])\n",
      "Tokens to generate: 256\n",
      "Elapsed time: 2.4651 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([256, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 256, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1281, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.1/tests/threshold_02/short_cord_progression.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:17<00:15,  7.83s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([1361, 24])\n",
      "sequence with start token tensor: torch.Size([1362, 24])\n",
      "context_seq tensor: torch.Size([1, 1025, 24])\n",
      "continuing seq torch.Size([1, 337, 24])\n",
      "Tokens to generate: 337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:21<00:05,  5.83s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3.2541 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([337, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 337, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1362, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.1/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([2480, 24])\n",
      "sequence with start token tensor: torch.Size([2481, 24])\n",
      "context_seq tensor: torch.Size([1, 1025, 24])\n",
      "continuing seq torch.Size([1, 1456, 24])\n",
      "Tokens to generate: 1456\n",
      "Elapsed time: 13.9544 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1456, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1456, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2481, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [00:35<00:00,  9.16s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [00:35<00:00, 35.59s/it]\u001B[A\n",
      "Projects:  35%|███▍      | 8/23 [02:26<05:56, 23.74s/it]             \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.1/tests/threshold_02/raindrop_prelude.mid\n",
      "\n",
      "==============================\n",
      "Testing model transformer_1.3\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.3\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 101, 24])\n",
      "continuing seq torch.Size([1, 2460, 24])\n",
      "Tokens to generate: 2460\n",
      "Elapsed time: 4.0180 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2460, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2460, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.3/tests/threshold_02/simple_test.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:04<00:12,  4.28s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([1280, 24])\n",
      "sequence with start token tensor: torch.Size([1281, 24])\n",
      "context_seq tensor: torch.Size([1, 101, 24])\n",
      "continuing seq torch.Size([1, 1180, 24])\n",
      "Tokens to generate: 1180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:06<00:06,  3.02s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.9896 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1180, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1180, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1281, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.3/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([1361, 24])\n",
      "sequence with start token tensor: torch.Size([1362, 24])\n",
      "context_seq tensor: torch.Size([1, 101, 24])\n",
      "continuing seq torch.Size([1, 1261, 24])\n",
      "Tokens to generate: 1261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:08<00:02,  2.67s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 2.1039 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1261, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1261, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1362, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.3/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([2480, 24])\n",
      "sequence with start token tensor: torch.Size([2481, 24])\n",
      "context_seq tensor: torch.Size([1, 101, 24])\n",
      "continuing seq torch.Size([1, 2380, 24])\n",
      "Tokens to generate: 2380\n",
      "Elapsed time: 3.9016 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2380, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2380, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2481, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.3/tests/threshold_02/raindrop_prelude.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [00:12<00:00,  3.25s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [00:12<00:00, 12.82s/it]\u001B[A\n",
      "Projects:  39%|███▉      | 9/23 [02:39<04:47, 20.57s/it]             \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Testing model transformer_1.4\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.4\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 51, 24])\n",
      "continuing seq torch.Size([1, 2510, 24])\n",
      "Tokens to generate: 2510\n",
      "Elapsed time: 3.4853 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2510, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2510, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:03<00:11,  3.75s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.4/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([1280, 24])\n",
      "sequence with start token tensor: torch.Size([1281, 24])\n",
      "context_seq tensor: torch.Size([1, 51, 24])\n",
      "continuing seq torch.Size([1, 1230, 24])\n",
      "Tokens to generate: 1230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:05<00:05,  2.64s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.7211 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1230, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1230, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1281, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.4/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([1361, 24])\n",
      "sequence with start token tensor: torch.Size([1362, 24])\n",
      "context_seq tensor: torch.Size([1, 51, 24])\n",
      "continuing seq torch.Size([1, 1311, 24])\n",
      "Tokens to generate: 1311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:07<00:02,  2.32s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.8062 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1311, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1311, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1362, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.4/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([2480, 24])\n",
      "sequence with start token tensor: torch.Size([2481, 24])\n",
      "context_seq tensor: torch.Size([1, 51, 24])\n",
      "continuing seq torch.Size([1, 2430, 24])\n",
      "Tokens to generate: 2430\n",
      "Elapsed time: 3.4025 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2430, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2430, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2481, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [00:11<00:00,  2.86s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [00:11<00:00, 11.26s/it]\u001B[A\n",
      "Projects:  43%|████▎     | 10/23 [02:52<03:53, 17.97s/it]            \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.4/tests/threshold_02/raindrop_prelude.mid\n",
      "\n",
      "==============================\n",
      "Testing model transformer_1.5\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.5\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 201, 24])\n",
      "continuing seq torch.Size([1, 2360, 24])\n",
      "Tokens to generate: 2360\n",
      "Elapsed time: 5.7981 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2360, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2360, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:06<00:18,  6.07s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.5/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([1280, 24])\n",
      "sequence with start token tensor: torch.Size([1281, 24])\n",
      "context_seq tensor: torch.Size([1, 201, 24])\n",
      "continuing seq torch.Size([1, 1080, 24])\n",
      "Tokens to generate: 1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:08<00:08,  4.13s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 2.6140 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1080, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1080, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1281, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.5/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([1361, 24])\n",
      "sequence with start token tensor: torch.Size([1362, 24])\n",
      "context_seq tensor: torch.Size([1, 201, 24])\n",
      "continuing seq torch.Size([1, 1161, 24])\n",
      "Tokens to generate: 1161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:11<00:03,  3.60s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 2.8095 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1161, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1161, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1362, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.5/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([2480, 24])\n",
      "sequence with start token tensor: torch.Size([2481, 24])\n",
      "context_seq tensor: torch.Size([1, 201, 24])\n",
      "continuing seq torch.Size([1, 2280, 24])\n",
      "Tokens to generate: 2280\n",
      "Elapsed time: 5.4632 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2280, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2280, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2481, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [00:17<00:00,  4.45s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [00:17<00:00, 17.57s/it]\u001B[A\n",
      "Projects:  48%|████▊     | 11/23 [03:10<03:37, 18.09s/it]            \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.5/tests/threshold_02/raindrop_prelude.mid\n",
      "\n",
      "==============================\n",
      "Testing model transformer_1.6\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.6\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 2048, 24])\n",
      "Tokens to generate: 2048\n",
      "Elapsed time: 31.7571 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2048, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2048, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:32<01:36, 32.08s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.6/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([1280, 24])\n",
      "sequence with start token tensor: torch.Size([1281, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 768, 24])\n",
      "Tokens to generate: 768\n",
      "Elapsed time: 12.4163 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([768, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 768, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1281, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.6/tests/threshold_02/short_cord_progression.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:44<00:41, 20.64s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([1361, 24])\n",
      "sequence with start token tensor: torch.Size([1362, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 849, 24])\n",
      "Tokens to generate: 849\n",
      "Elapsed time: 12.4460 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([849, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 849, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1362, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.6/tests/threshold_02/moritz_maria.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:57<00:16, 16.99s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2480, 24])\n",
      "sequence with start token tensor: torch.Size([2481, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 1968, 24])\n",
      "Tokens to generate: 1968\n",
      "Elapsed time: 29.0597 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1968, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1968, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2481, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [01:26<00:00, 21.88s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [01:26<00:00, 86.74s/it]\u001B[A\n",
      "Projects:  52%|█████▏    | 12/23 [04:39<07:15, 39.58s/it]            \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.6/tests/threshold_02/raindrop_prelude.mid\n",
      "\n",
      "==============================\n",
      "Testing model transformer_1.7\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.7\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 2048, 24])\n",
      "Tokens to generate: 2048\n",
      "Elapsed time: 1.4225 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2048, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2048, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:01<00:05,  1.69s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.7/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([1280, 24])\n",
      "sequence with start token tensor: torch.Size([1281, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 768, 24])\n",
      "Tokens to generate: 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:02<00:02,  1.10s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.5365 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([768, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 768, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1281, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.7/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([1361, 24])\n",
      "sequence with start token tensor: torch.Size([1362, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 849, 24])\n",
      "Tokens to generate: 849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:03<00:00,  1.08it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.5686 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([849, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 849, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1362, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.7/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([2480, 24])\n",
      "sequence with start token tensor: torch.Size([2481, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 1968, 24])\n",
      "Tokens to generate: 1968\n",
      "Elapsed time: 1.3418 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1968, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1968, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2481, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [00:04<00:00,  1.22s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [00:04<00:00,  4.76s/it]\u001B[A\n",
      "Projects:  57%|█████▋    | 13/23 [04:44<04:50, 29.09s/it]            \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.7/tests/threshold_02/raindrop_prelude.mid\n",
      "\n",
      "==============================\n",
      "Testing model transformer_2.0\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_2.0\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 1025, 24])\n",
      "continuing seq torch.Size([1, 1536, 24])\n",
      "Tokens to generate: 1536\n",
      "Elapsed time: 14.7898 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1536, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1536, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:15<00:45, 15.12s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_2.0/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([1280, 24])\n",
      "sequence with start token tensor: torch.Size([1281, 24])\n",
      "context_seq tensor: torch.Size([1, 1025, 24])\n",
      "continuing seq torch.Size([1, 256, 24])\n",
      "Tokens to generate: 256\n",
      "Elapsed time: 2.4324 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([256, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 256, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1281, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_2.0/tests/threshold_02/short_cord_progression.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:17<00:15,  7.78s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([1361, 24])\n",
      "sequence with start token tensor: torch.Size([1362, 24])\n",
      "context_seq tensor: torch.Size([1, 1025, 24])\n",
      "continuing seq torch.Size([1, 337, 24])\n",
      "Tokens to generate: 337\n",
      "Elapsed time: 3.2311 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([337, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 337, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1362, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_2.0/tests/threshold_02/moritz_maria.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:21<00:05,  5.80s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2480, 24])\n",
      "sequence with start token tensor: torch.Size([2481, 24])\n",
      "context_seq tensor: torch.Size([1, 1025, 24])\n",
      "continuing seq torch.Size([1, 1456, 24])\n",
      "Tokens to generate: 1456\n",
      "Elapsed time: 13.8640 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1456, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1456, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2481, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [00:35<00:00,  9.12s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [00:35<00:00, 35.42s/it]\u001B[A\n",
      "Projects:  61%|██████    | 14/23 [05:20<04:41, 31.25s/it]            \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_2.0/tests/threshold_02/raindrop_prelude.mid\n",
      "\n",
      "==============================\n",
      "Testing model transformer_1.9\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.9\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([5119, 24])\n",
      "sequence with start token tensor: torch.Size([5120, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 4607, 24])\n",
      "Tokens to generate: 4607\n",
      "Elapsed time: 1.3498 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([4607, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 4607, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 5120, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:01<00:05,  1.87s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.9/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 2048, 24])\n",
      "Tokens to generate: 2048\n",
      "Elapsed time: 0.6563 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2048, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2048, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:02<00:02,  1.32s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.9/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([2722, 24])\n",
      "sequence with start token tensor: torch.Size([2723, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 2210, 24])\n",
      "Tokens to generate: 2210\n",
      "Elapsed time: 0.6426 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2210, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2210, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2723, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:03<00:01,  1.17s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.9/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([4959, 24])\n",
      "sequence with start token tensor: torch.Size([4960, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 4447, 24])\n",
      "Tokens to generate: 4447\n",
      "Elapsed time: 1.2676 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([4447, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 4447, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 4960, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [00:05<00:00,  1.45s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [00:05<00:00,  5.67s/it]\u001B[A\n",
      "Projects:  65%|██████▌   | 15/23 [05:26<03:09, 23.65s/it]            \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.9/tests/threshold_02/raindrop_prelude.mid\n",
      "\n",
      "==============================\n",
      "Testing model transformer_3.0\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_3.0\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([5119, 24])\n",
      "sequence with start token tensor: torch.Size([5120, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 4607, 24])\n",
      "Tokens to generate: 4607\n",
      "Elapsed time: 22.0316 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([4607, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 4607, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 5120, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:22<01:07, 22.57s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_3.0/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 2048, 24])\n",
      "Tokens to generate: 2048\n",
      "Elapsed time: 10.2126 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2048, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2048, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:33<00:31, 15.50s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_3.0/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([2722, 24])\n",
      "sequence with start token tensor: torch.Size([2723, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 2210, 24])\n",
      "Tokens to generate: 2210\n",
      "Elapsed time: 10.3929 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2210, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2210, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2723, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:43<00:13, 13.31s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_3.0/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([4959, 24])\n",
      "sequence with start token tensor: torch.Size([4960, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 4447, 24])\n",
      "Tokens to generate: 4447\n",
      "Elapsed time: 21.9788 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([4447, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 4447, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 4960, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [01:06<00:00, 16.94s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [01:06<00:00, 66.33s/it]\u001B[A\n",
      "Projects:  70%|██████▉   | 16/23 [06:33<04:17, 36.79s/it]            \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_3.0/tests/threshold_02/raindrop_prelude.mid\n",
      "\n",
      "==============================\n",
      "Testing model transformer_3.1\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_3.1\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([5119, 24])\n",
      "sequence with start token tensor: torch.Size([5120, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 4607, 24])\n",
      "Tokens to generate: 4607\n",
      "Elapsed time: 3.5313 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([4607, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 4607, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 5120, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:04<00:12,  4.06s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_3.1/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 2048, 24])\n",
      "Tokens to generate: 2048\n",
      "Elapsed time: 1.4829 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2048, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2048, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:05<00:05,  2.71s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_3.1/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([2722, 24])\n",
      "sequence with start token tensor: torch.Size([2723, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 2210, 24])\n",
      "Tokens to generate: 2210\n",
      "Elapsed time: 1.6050 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2210, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2210, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2723, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:07<00:02,  2.35s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_3.1/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([4959, 24])\n",
      "sequence with start token tensor: torch.Size([4960, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 4447, 24])\n",
      "Tokens to generate: 4447\n",
      "Elapsed time: 3.0848 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([4447, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 4447, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 4960, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [00:11<00:00,  2.87s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [00:11<00:00, 11.42s/it]\u001B[A\n",
      "Projects:  74%|███████▍  | 17/23 [06:45<02:55, 29.26s/it]            \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_3.1/tests/threshold_02/raindrop_prelude.mid\n",
      "\n",
      "==============================\n",
      "Testing model transformer_1.10\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.10\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 2048, 24])\n",
      "Tokens to generate: 2048\n",
      "Elapsed time: 0.5923 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2048, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2048, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:00<00:02,  1.11it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.10/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([1280, 24])\n",
      "sequence with start token tensor: torch.Size([1281, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 768, 24])\n",
      "Tokens to generate: 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:01<00:01,  1.69it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.2221 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([768, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 768, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1281, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.10/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([1361, 24])\n",
      "sequence with start token tensor: torch.Size([1362, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 849, 24])\n",
      "Tokens to generate: 849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:01<00:00,  2.00it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.2432 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([849, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 849, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1362, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.10/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([2480, 24])\n",
      "sequence with start token tensor: torch.Size([2481, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 1968, 24])\n",
      "Tokens to generate: 1968\n",
      "Elapsed time: 0.5600 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1968, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1968, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2481, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [00:02<00:00,  1.60it/s]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [00:02<00:00,  2.49s/it]\u001B[A\n",
      "Projects:  78%|███████▊  | 18/23 [06:48<01:46, 21.27s/it]            \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.10/tests/threshold_02/raindrop_prelude.mid\n",
      "\n",
      "==============================\n",
      "Testing model transformer_1.8\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.8\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([512, 24])\n",
      "sequence with start token tensor: torch.Size([513, 24])\n",
      "context_seq tensor: torch.Size([1, 103, 24])\n",
      "continuing seq torch.Size([1, 410, 24])\n",
      "Tokens to generate: 410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:00<00:02,  1.41it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.6417 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([410, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 410, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 513, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.8/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([256, 24])\n",
      "sequence with start token tensor: torch.Size([257, 24])\n",
      "context_seq tensor: torch.Size([1, 103, 24])\n",
      "continuing seq torch.Size([1, 154, 24])\n",
      "Tokens to generate: 154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:01<00:00,  2.16it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.2515 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([154, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 154, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 257, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.8/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([272, 24])\n",
      "sequence with start token tensor: torch.Size([273, 24])\n",
      "context_seq tensor: torch.Size([1, 103, 24])\n",
      "continuing seq torch.Size([1, 170, 24])\n",
      "Tokens to generate: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:01<00:00,  2.49it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.2867 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([170, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 170, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 273, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.8/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([496, 24])\n",
      "sequence with start token tensor: torch.Size([497, 24])\n",
      "context_seq tensor: torch.Size([1, 103, 24])\n",
      "continuing seq torch.Size([1, 394, 24])\n",
      "Tokens to generate: 394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [00:02<00:00,  1.83it/s]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\u001B[A\n",
      "Projects:  83%|████████▎ | 19/23 [06:50<01:02, 15.69s/it]            \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.6977 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([394, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 394, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 497, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.8/tests/threshold_02/raindrop_prelude.mid\n",
      "\n",
      "==============================\n",
      "Testing model transformer_1.11\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.11\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([5119, 24])\n",
      "sequence with start token tensor: torch.Size([5120, 24])\n",
      "context_seq tensor: torch.Size([1, 2049, 24])\n",
      "continuing seq torch.Size([1, 3071, 24])\n",
      "Tokens to generate: 3071\n",
      "Elapsed time: 92.7598 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([3071, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 3071, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 5120, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [01:33<04:40, 93.49s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.11/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 2049, 24])\n",
      "continuing seq torch.Size([1, 512, 24])\n",
      "Tokens to generate: 512\n",
      "Elapsed time: 15.0328 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([512, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 512, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [01:49<01:35, 47.63s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.11/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([2722, 24])\n",
      "sequence with start token tensor: torch.Size([2723, 24])\n",
      "context_seq tensor: torch.Size([1, 2049, 24])\n",
      "continuing seq torch.Size([1, 674, 24])\n",
      "Tokens to generate: 674\n",
      "Elapsed time: 19.5787 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([674, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 674, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2723, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [02:09<00:35, 35.02s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.11/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([4959, 24])\n",
      "sequence with start token tensor: torch.Size([4960, 24])\n",
      "context_seq tensor: torch.Size([1, 2049, 24])\n",
      "continuing seq torch.Size([1, 2911, 24])\n",
      "Tokens to generate: 2911\n",
      "Elapsed time: 87.4599 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2911, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2911, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 4960, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [03:37<00:00, 55.98s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [03:37<00:00, 217.14s/it]\u001B[A\n",
      "Projects:  87%|████████▋ | 20/23 [10:28<03:49, 76.45s/it]             \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.11/tests/threshold_02/raindrop_prelude.mid\n",
      "\n",
      "==============================\n",
      "Testing model transformer_3.2\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_3.2\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 2048, 24])\n",
      "Tokens to generate: 2048\n",
      "Elapsed time: 9.4515 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2048, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2048, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:09<00:29,  9.75s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_3.2/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([1280, 24])\n",
      "sequence with start token tensor: torch.Size([1281, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 768, 24])\n",
      "Tokens to generate: 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:13<00:12,  6.17s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3.4877 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([768, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 768, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1281, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_3.2/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([1361, 24])\n",
      "sequence with start token tensor: torch.Size([1362, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 849, 24])\n",
      "Tokens to generate: 849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [00:17<00:05,  5.20s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3.8865 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([849, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 849, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 1362, 24])\n",
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_3.2/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([2480, 24])\n",
      "sequence with start token tensor: torch.Size([2481, 24])\n",
      "context_seq tensor: torch.Size([1, 513, 24])\n",
      "continuing seq torch.Size([1, 1968, 24])\n",
      "Tokens to generate: 1968\n",
      "Elapsed time: 9.0640 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1968, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1968, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2481, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [00:26<00:00,  6.85s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [00:26<00:00, 26.84s/it]\u001B[A\n",
      "Projects:  91%|█████████▏| 21/23 [10:56<02:03, 61.80s/it]            \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_3.2/tests/threshold_02/raindrop_prelude.mid\n",
      "\n",
      "==============================\n",
      "Testing model transformer_1.12\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.12\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([5119, 24])\n",
      "sequence with start token tensor: torch.Size([5120, 24])\n",
      "context_seq tensor: torch.Size([1, 1025, 24])\n",
      "continuing seq torch.Size([1, 4095, 24])\n",
      "Tokens to generate: 4095\n",
      "Elapsed time: 38.8055 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([4095, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 4095, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 5120, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [00:39<01:58, 39.35s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.12/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 1025, 24])\n",
      "continuing seq torch.Size([1, 1536, 24])\n",
      "Tokens to generate: 1536\n",
      "Elapsed time: 14.9824 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1536, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1536, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [00:54<00:50, 25.23s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.12/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([2722, 24])\n",
      "sequence with start token tensor: torch.Size([2723, 24])\n",
      "context_seq tensor: torch.Size([1, 1025, 24])\n",
      "continuing seq torch.Size([1, 1698, 24])\n",
      "Tokens to generate: 1698\n",
      "Elapsed time: 16.3678 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([1698, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 1698, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2723, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [01:11<00:21, 21.38s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.12/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([4959, 24])\n",
      "sequence with start token tensor: torch.Size([4960, 24])\n",
      "context_seq tensor: torch.Size([1, 1025, 24])\n",
      "continuing seq torch.Size([1, 3935, 24])\n",
      "Tokens to generate: 3935\n",
      "Elapsed time: 42.8452 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([3935, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 3935, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 4960, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [01:55<00:00, 30.14s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [01:55<00:00, 115.05s/it]\u001B[A\n",
      "Projects:  96%|█████████▌| 22/23 [12:52<01:18, 78.03s/it]             \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.12/tests/threshold_02/raindrop_prelude.mid\n",
      "\n",
      "==============================\n",
      "Testing model transformer_1.11_overfitted\n",
      "At location /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.11_overfitted\n",
      "==============================\n",
      "\n",
      "Best epoch is epoch number 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configurations:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Songs:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequecne tensor: torch.Size([5119, 24])\n",
      "sequence with start token tensor: torch.Size([5120, 24])\n",
      "context_seq tensor: torch.Size([1, 2049, 24])\n",
      "continuing seq torch.Size([1, 3071, 24])\n",
      "Tokens to generate: 3071\n",
      "Elapsed time: 90.0391 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([3071, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 3071, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 5120, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  25%|██▌       | 1/4 [01:30<04:32, 90.70s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.11_overfitted/tests/threshold_02/simple_test.mid\n",
      "sequecne tensor: torch.Size([2560, 24])\n",
      "sequence with start token tensor: torch.Size([2561, 24])\n",
      "context_seq tensor: torch.Size([1, 2049, 24])\n",
      "continuing seq torch.Size([1, 512, 24])\n",
      "Tokens to generate: 512\n",
      "Elapsed time: 14.5933 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([512, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 512, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2561, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  50%|█████     | 2/4 [01:45<01:32, 46.21s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.11_overfitted/tests/threshold_02/short_cord_progression.mid\n",
      "sequecne tensor: torch.Size([2722, 24])\n",
      "sequence with start token tensor: torch.Size([2723, 24])\n",
      "context_seq tensor: torch.Size([1, 2049, 24])\n",
      "continuing seq torch.Size([1, 674, 24])\n",
      "Tokens to generate: 674\n",
      "Elapsed time: 20.5087 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([674, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 674, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 2723, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs:  75%|███████▌  | 3/4 [02:06<00:34, 34.67s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.11_overfitted/tests/threshold_02/moritz_maria.mid\n",
      "sequecne tensor: torch.Size([4959, 24])\n",
      "sequence with start token tensor: torch.Size([4960, 24])\n",
      "context_seq tensor: torch.Size([1, 2049, 24])\n",
      "continuing seq torch.Size([1, 2911, 24])\n",
      "Tokens to generate: 2911\n",
      "Elapsed time: 85.3196 seconds\n",
      "Binary Tensors after concatinating:  torch.Size([2911, 24])\n",
      "Binary Tensors after unsqueezing:  torch.Size([1, 2911, 24])\n",
      "Context sequence + Generated tokens:  torch.Size([1, 4960, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Songs: 100%|██████████| 4/4 [03:32<00:00, 54.94s/it]\u001B[A\u001B[A\n",
      "\n",
      "                                                    \u001B[A\u001B[A\n",
      "Testing configurations: 100%|██████████| 1/1 [03:32<00:00, 212.72s/it]\u001B[A\n",
      "                                                                      \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved to /home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/transformer_1.11_overfitted/tests/threshold_02/raindrop_prelude.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
