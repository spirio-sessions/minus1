{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Jetzt nochmal ein Decoder only ohne tokenization zu int mit hoffentlich korrekter inferenz\n",
   "id": "24c38489ff10921a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T22:10:03.916262Z",
     "start_time": "2024-06-25T22:10:03.308083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from data_preperation import dataset_snapshot\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ],
   "id": "bcb65d87ee74abdb",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# prepare data",
   "id": "23765b3ac55ffd27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T22:10:03.923212Z",
     "start_time": "2024-06-25T22:10:03.916912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if GPU is available, set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
   ],
   "id": "7fa52c1cc923a11e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T22:10:04.018384Z",
     "start_time": "2024-06-25T22:10:03.923726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set Special tokens, chunk size, etc.\n",
    "sos_token = np.full((1, 88), 1)\n",
    "pad_token = np.full((1, 88), 2)\n",
    "pad_token = torch.tensor(pad_token, device=device)\n",
    "\n",
    "seq_length = 512\n",
    "batch_size = 64"
   ],
   "id": "4c76896becf6ab2e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T22:10:25.441947Z",
     "start_time": "2024-06-25T22:10:04.019400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformer_decoder_training.dataprep_transformer import dataprep_1\n",
    "from sklearn.model_selection import train_test_split\n",
    "# prepare data for dataset\n",
    "\n",
    "#load data\n",
    "dataset_as_snapshots = dataset_snapshot.process_dataset_multithreaded(\"/home/falaxdb/Repos/minus1/datasets/maestro_v3_split/hands_split_into_seperate_midis\", 0.05)\n",
    "# filter snapshots to 88 piano notes\n",
    "dataset_as_snapshots = dataset_snapshot.filter_piano_range(dataset_as_snapshots)\n",
    "\n",
    "# Convert data into Chunks and add special tokens\n",
    "data = dataprep_1.prepare_dataset(dataset_as_snapshots, seq_length, seq_length, sos_token)\n",
    "\n",
    "print(\"Ammount of sequence pairs:\", len(data))\n",
    "\n",
    "# Split the dataset using sklearn while maintaining pairs\n",
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42, shuffle=True)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, shuffle=True)"
   ],
   "id": "20e83bfc1b5fcdb1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed dataset (1038/1038): 100%|██████████| 1038/1038 [00:14<00:00, 71.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1038 of 1038 files\n",
      "Ammount of sequence pairs: 10069\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T22:10:26.061779Z",
     "start_time": "2024-06-25T22:10:25.442454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformer_decoder_training.dataset_transformer.dataset_1 import PianoDataset\n",
    "\n",
    "# Create custom datasets\n",
    "train_dataset = PianoDataset(train_data)\n",
    "val_dataset = PianoDataset(val_data)\n",
    "test_dataset = PianoDataset(test_data)\n",
    "\n",
    "# Create DataLoaders for each subset with drop_last=True\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "# Iterate over the DataLoader (example with train_loader)\n",
    "for batch in train_loader:\n",
    "    X, y = batch\n",
    "    print(X.shape, y.shape)\n",
    "    # X and y should both have shape (batch_size, chunk_size + 1, feature dimension) because of SOS (and EOS) tokens"
   ],
   "id": "5facbd248fd5eb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n",
      "torch.Size([64, 513, 88]) torch.Size([64, 513, 88])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Initialize model",
   "id": "e92d52061114bca6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T22:10:26.063931Z",
     "start_time": "2024-06-25T22:10:26.062388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set parameters\n",
    "\n",
    "# Learning rate for the optimizer\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Number of epochs for training\n",
    "nepochs = 20\n",
    "\n",
    "# Embedding Size\n",
    "hidden_size = 256\n",
    "\n",
    "# Number of transformer blocks\n",
    "num_layers = 8\n",
    "\n",
    "# MultiheadAttention Heads\n",
    "num_heads = 8"
   ],
   "id": "bfbeb949c8aaa4d2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T22:10:26.890291Z",
     "start_time": "2024-06-25T22:10:26.064366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformer_decoder_training.models.transformer_decoder_1 import Transformer\n",
    "\n",
    "# Create model\n",
    "# (num emb = wie viele verschiedene Tokens es geben kann bei 12 Tönen 2 ** 12 Möglichkeiten + 2 special tokens)\n",
    "# num_emb: Da ja keine int indexe mehr -> wahrscheinlich 88 wegen 88 Keys\n",
    "tf_generator = Transformer(num_emb=88, num_layers=num_layers, \n",
    "                           hidden_size=hidden_size, num_heads=num_heads).to(device)\n",
    "# Initialize the optimizer with above parameters\n",
    "optimizer = optim.Adam(tf_generator.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the loss function\n",
    "# Klammern nicht vergessen\n",
    "loss_fn = nn.BCELoss()"
   ],
   "id": "b4645664ec62fb7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T22:10:26.892853Z",
     "start_time": "2024-06-25T22:10:26.890759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check number of model parameters\n",
    "num_model_params = 0\n",
    "for param in tf_generator.parameters():\n",
    "    num_model_params += param.flatten().shape[0]\n",
    "\n",
    "print(\"-This Model Has %d (Approximately %d Million) Parameters!\" % (num_model_params, num_model_params//1e6))"
   ],
   "id": "d8b97651371e006a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-This Model Has 6363480 (Approximately 6 Million) Parameters!\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "1891247df0d89ca1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T22:10:26.900743Z",
     "start_time": "2024-06-25T22:10:26.893245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_loop(model, opt, loss_fn, dataloader, pad_token, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        # Move data to GPU\n",
    "        input_melody, expected_harmony = batch\n",
    "        input_melody, expected_harmony = input_melody.to(device), expected_harmony.to(device)\n",
    "        \n",
    "        # shift input und output für das training zeug mit start token\n",
    "        input_melody = input_melody[:, 0:-1]\n",
    "        expected_harmony = expected_harmony[:, 1:]\n",
    "        \n",
    "        # Generate predictions\n",
    "        pred = tf_generator(input_melody, pad_token)\n",
    "        \n",
    "        #print(\"Prediction shape:\", pred.shape)\n",
    "        #print(pred)\n",
    "        #print(\"expected harmony_shape:\", expected_harmony.shape)\n",
    "        #print(expected_harmony)\n",
    "        \n",
    "        # Calculate loss with masked cross-entropy\n",
    "        # ich glaube 0 steht in vorlage für padding token index -> habe ich hier anders\n",
    "        #mask = (expected_harmony != pad_token).float() Maske verwenden, um Padding positions im output zu canceln\n",
    "        # masked_pred = pred * mask\n",
    "        loss = loss_fn(pred, expected_harmony)\n",
    "        \n",
    "        # Backpropagation\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "        total_loss += loss.detach().item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ],
   "id": "1f09bcbc20cb6ee4",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T22:14:19.098469Z",
     "start_time": "2024-06-25T22:10:26.901831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_loop(tf_generator, optimizer, loss_fn, train_loader, pad_token, device)\n",
    "    end_time = timer()\n",
    "    # val_loss = validation_loop(model, loss_fn, val_loader)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f} \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n"
   ],
   "id": "9fc6d5036b353801",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 0.076 Epoch time = 23.436s\n",
      "Epoch: 2, Train loss: 0.049 Epoch time = 23.168s\n",
      "Epoch: 3, Train loss: 0.049 Epoch time = 23.173s\n",
      "Epoch: 4, Train loss: 0.049 Epoch time = 23.182s\n",
      "Epoch: 5, Train loss: 0.048 Epoch time = 23.215s\n",
      "Epoch: 6, Train loss: 0.048 Epoch time = 23.206s\n",
      "Epoch: 7, Train loss: 0.048 Epoch time = 23.220s\n",
      "Epoch: 8, Train loss: 0.047 Epoch time = 23.188s\n",
      "Epoch: 9, Train loss: 0.046 Epoch time = 23.174s\n",
      "Epoch: 10, Train loss: 0.045 Epoch time = 23.226s\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T22:14:19.118168Z",
     "start_time": "2024-06-25T22:14:19.099196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# see: https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html#saving-and-loading-models-with-shapes\n",
    "\n",
    "torch.save(tf_generator, \"./saved_models/model_1_notebook_v5.pth\")"
   ],
   "id": "364f0e3645599da",
   "outputs": [],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
