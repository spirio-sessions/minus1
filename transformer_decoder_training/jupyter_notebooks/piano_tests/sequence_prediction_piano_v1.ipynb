{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Jetzt der 1. Versuch für unsere eigenen Piano-Daten",
   "id": "197553aeb005392a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 0. Imports",
   "id": "f89af126ceadd9d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T14:50:03.419209Z",
     "start_time": "2024-06-17T14:50:03.417113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import random"
   ],
   "id": "d5b1741eeb343552",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "gpu nutzen",
   "id": "14567bc9b1cf5791"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T14:50:03.460125Z",
     "start_time": "2024-06-17T14:50:03.457920Z"
    }
   },
   "cell_type": "code",
   "source": "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
   "id": "41ff7d21d02866ef",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. Daten Vorbereiten\n",
    "\n",
    "## Ideen für Special Tokens\n",
    "\n",
    "Padding, Start of Stream (SOS), und End of Stream (EOS) Tokens sind wichtige Konzepte beim Arbeiten mit Sequenzdaten, insbesondere in Modellen wie Transformern. Sie helfen dabei, Sequenzen auf eine einheitliche Länge zu bringen und dem Modell zu signalisieren, wann eine Eingabe- oder Ausgabesequenz beginnt und endet.\n",
    "\n",
    "### Padding Token\n",
    "\n",
    "- **Padding Token** wird verwendet, um alle Sequenzen auf eine einheitliche Länge zu bringen.\n",
    "- Da Ihre Daten aus binären Vektoren bestehen, könnte ein Padding Token einfach ein Vektor aus Nullen sein (d.h. kein Tastendruck).\n",
    "\n",
    "### Start of Stream (SOS) Token\n",
    "\n",
    "- **Start of Stream Token** signalisiert den Beginn einer Sequenz.\n",
    "- Ein möglicher SOS-Token könnte ein Vektor sein, bei dem nur das erste Element auf 1 gesetzt ist und der Rest auf 0 (d.h. `[1, 0, 0, ..., 0]`).\n",
    "\n",
    "### End of Stream (EOS) Token\n",
    "\n",
    "- **End of Stream Token** signalisiert das Ende einer Sequenz.\n",
    "- Ein möglicher EOS-Token könnte ein Vektor sein, bei dem nur das letzte Element auf 1 gesetzt ist und der Rest auf 0 (d.h. `[0, 0, ..., 0, 1]`).\n",
    "\n",
    "\n",
    "## Datenaufteilung\n",
    "\n",
    "- Wie Sollen die Daten am besten aufgeteilt werden? nach den einzelnen Songs? erst in Sequenzen aufteilen und dann splitten?\n",
    "- Alle songs sind verschieden lang -> in Sequenzen aufteilen und zu kurze sequenzen wegwerfen? oder lieber padden\n",
    "- Wann sollen die Start-of stream und end of stream tokens eingeführt werden -> wahrscheinlich für jede Sequenz.\n",
    "    - Bei der Inferenz dann halt schauen, weil Modell hat ja nur die Bestimmte sequenzlänge gelernt.\n",
    "\n",
    "- Ich mach eine Sequenzlänge von 50 Snapshots -> bei 0.1 pro snapshot also 5 Sekunden"
   ],
   "id": "247bf734d58c4b04"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.1 Definiere Code zum laden der Daten",
   "id": "b77709120b8d7467"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T14:50:03.535889Z",
     "start_time": "2024-06-17T14:50:03.461126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mido\n",
    "import os\n",
    "import fnmatch\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "\n",
    "def snapshot_active_notes_from_midi(file_path, interval):\n",
    "    \"\"\"\n",
    "    Processes a MIDI file and returns snapshots of active notes at specified intervals.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the MIDI file.\n",
    "        interval (float): The interval (in seconds) at which snapshots are taken.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An array of snapshots, where each snapshot is a list of active notes.\n",
    "    \"\"\"\n",
    "    mid = mido.MidiFile(file_path)\n",
    "    snapshots = []\n",
    "    active_notes = [0] * 128\n",
    "    current_time = 0\n",
    "    snapshot_time = 0\n",
    "    previous_event_time = 0\n",
    "\n",
    "    for msg in mid:\n",
    "        current_time += msg.time\n",
    "\n",
    "        while current_time >= snapshot_time + interval:\n",
    "            if current_time == previous_event_time:\n",
    "                break\n",
    "            snapshots.append(active_notes[:])\n",
    "            snapshot_time += interval\n",
    "\n",
    "        if msg.type == 'note_on':\n",
    "            if msg.velocity == 0:\n",
    "                active_notes[msg.note] = 0\n",
    "            else:\n",
    "                active_notes[msg.note] = 1\n",
    "        elif msg.type == 'note_off':\n",
    "            active_notes[msg.note] = 0\n",
    "\n",
    "        previous_event_time = current_time\n",
    "\n",
    "    return np.array(snapshots)\n",
    "\n",
    "\n",
    "def find_midi_files(root_dir, pattern=None):\n",
    "    \"\"\"\n",
    "    Recursively searches for MIDI files in the specified root directory and groups them\n",
    "    based on their base patterns, ensuring each group has exactly one 'rightH' and one 'leftH' file.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): The root directory to start the search.\n",
    "        pattern (str, optional): An optional pattern to filter the MIDI files. Only files\n",
    "                                 containing this pattern in their names will be included.\n",
    "\n",
    "    Returns:\n",
    "        defaultdict: A dictionary where each key is a base pattern and the value is a dictionary\n",
    "                     with 'rightH' and 'leftH' keys for corresponding file paths.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If any group does not have both 'rightH' and 'leftH' MIDI files.\n",
    "\n",
    "    Example:\n",
    "        midi_files = find_midi_files('/path/to/root_dir')\n",
    "        for base_pattern, files in midi_files.items():\n",
    "            print(f\"Group: {base_pattern}\")\n",
    "            print(f\" - Right Hand: {files['rightH']}\")\n",
    "            print(f\" - Left Hand: {files['leftH']}\")\n",
    "    \"\"\"\n",
    "    midi_groups = defaultdict(dict)\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if fnmatch.fnmatch(filename.lower(), '*.midi') or fnmatch.fnmatch(filename.lower(), '*.mid'):\n",
    "                if pattern is None or fnmatch.fnmatch(filename.lower(), f'*{pattern.lower()}*'):\n",
    "                    filepath = os.path.join(dirpath, filename)\n",
    "                    parts = filename.lower().split('_')\n",
    "                    if 'righth' in parts[-1]:\n",
    "                        base_pattern = '_'.join(parts[:-1])\n",
    "                        midi_groups[base_pattern]['rightH'] = filepath\n",
    "                    elif 'lefth' in parts[-1]:\n",
    "                        base_pattern = '_'.join(parts[:-1])\n",
    "                        midi_groups[base_pattern]['leftH'] = filepath\n",
    "\n",
    "    # Ensure each group has exactly one 'rightH' and one 'leftH'\n",
    "    for base_pattern, files in midi_groups.items():\n",
    "        if 'rightH' not in files or 'leftH' not in files:\n",
    "            raise ValueError(f\"Group {base_pattern} does not have both 'rightH' and 'leftH' MIDI files.\")\n",
    "\n",
    "    return midi_groups\n",
    "\n",
    "\n",
    "def trim_snapshots(group_snapshots):\n",
    "    \"\"\"\n",
    "    Trims the leading and trailing empty snapshots for each group of snapshots.\n",
    "\n",
    "    Args:\n",
    "        group_snapshots (list): A list of numpy arrays where each array represents snapshots\n",
    "                                for a MIDI file in the group.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of trimmed numpy arrays with empty snapshots removed from the beginning and end.\n",
    "    \"\"\"\n",
    "    min_start = float('inf')\n",
    "    max_end = 0\n",
    "\n",
    "    for snapshots in group_snapshots:\n",
    "        non_empty_indices = np.where(snapshots.any(axis=1))[0]\n",
    "        if non_empty_indices.size > 0:\n",
    "            first_non_empty = non_empty_indices[0]\n",
    "            last_non_empty = non_empty_indices[-1]\n",
    "            if first_non_empty < min_start:\n",
    "                min_start = first_non_empty\n",
    "            if last_non_empty > max_end:\n",
    "                max_end = last_non_empty\n",
    "\n",
    "    trimmed_group_snapshots = [snapshots[min_start:max_end + 1] for snapshots in group_snapshots]\n",
    "\n",
    "    return trimmed_group_snapshots\n",
    "\n",
    "\n",
    "def __process_single_midi(midi_file, interval):\n",
    "    \"\"\"\n",
    "    Helper function to process a single MIDI file and return its snapshots.\n",
    "\n",
    "    Args:\n",
    "        midi_file (str): The path to the MIDI file.\n",
    "        interval (float): The interval (in seconds) at which snapshots are taken.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the MIDI file path and the array of snapshots.\n",
    "    \"\"\"\n",
    "    snapshots_array = snapshot_active_notes_from_midi(midi_file, interval)\n",
    "    return midi_file, snapshots_array\n",
    "\n",
    "\n",
    "def process_dataset(dataset_dir, interval, pattern=None, amount=0):\n",
    "    \"\"\"\n",
    "    Processes a dataset of MIDI files, taking snapshots of active notes at specified intervals\n",
    "    and grouping related files together.\n",
    "\n",
    "    Args:\n",
    "        dataset_dir (str): The directory containing the dataset of MIDI files.\n",
    "        interval (float): The interval (in seconds) at which snapshots are taken.\n",
    "        pattern (str, optional): An optional pattern to filter the MIDI files.\n",
    "        amount (int, optional): An optional amount of how many songs should be processed.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of snapshots for each group of MIDI files. The group will always have the right hand first [0]\n",
    "        and then the left hand [1]\n",
    "    \"\"\"\n",
    "    midi_files = find_midi_files(dataset_dir, pattern)\n",
    "\n",
    "    # limit amount of files\n",
    "    if amount > 0:\n",
    "        midi_files = {k: midi_files[k] for k in list(midi_files)[:amount]}\n",
    "\n",
    "    files_as_snapshots = []\n",
    "    filenames = []\n",
    "\n",
    "    total_files = sum(len(files) for files in midi_files.values())\n",
    "    progress_bar = tqdm(total=total_files)\n",
    "\n",
    "    for base_pattern, group_files in midi_files.items():\n",
    "        group_snapshots = []\n",
    "        for hand in ['rightH', 'leftH']:\n",
    "            midi_file = group_files[hand]\n",
    "            snapshots_array = snapshot_active_notes_from_midi(midi_file, interval)\n",
    "            group_snapshots.append(snapshots_array)\n",
    "            filenames.append(midi_file)\n",
    "            progress_bar.update(1)\n",
    "            progress_bar.set_description(f\"Processed dataset ({progress_bar.n}/{progress_bar.total})\")\n",
    "\n",
    "        trimmed_group_snapshots = trim_snapshots(group_snapshots)\n",
    "        files_as_snapshots.append(trimmed_group_snapshots)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    return files_as_snapshots\n",
    "\n",
    "\n",
    "def process_dataset_multithreaded(dataset_dir, interval, pattern=None, amount=0):\n",
    "    \"\"\"\n",
    "    Processes a dataset of MIDI files, taking snapshots of active notes at specified intervals,\n",
    "    grouping related files together, and using multithreading for efficiency.\n",
    "\n",
    "    Args:\n",
    "        dataset_dir (str): The directory containing the dataset of MIDI files.\n",
    "        interval (float): The interval (in seconds) at which snapshots are taken.\n",
    "        pattern (str, optional): An optional pattern to filter the MIDI files.\n",
    "        amount (int, optional): An optional amount of how many songs should be processed.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of snapshots for each group of MIDI files. The group will always have the right hand first [0]\n",
    "        and then the left hand [1]\n",
    "    \"\"\"\n",
    "    midi_files = find_midi_files(dataset_dir, pattern)\n",
    "\n",
    "    # limit ammount of files\n",
    "    if amount > 0:\n",
    "        midi_files = {k: midi_files[k] for k in list(midi_files)[:amount]}\n",
    "\n",
    "    files_as_snapshots = []\n",
    "\n",
    "    total_files = sum(len(files) for files in midi_files.values())\n",
    "    progress_bar = tqdm(total=total_files)\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        future_to_midi = {executor.submit(__process_single_midi, midi_file, interval): midi_file\n",
    "                          for group_files in midi_files.values() for midi_file in group_files.values()}\n",
    "\n",
    "        for future in concurrent.futures.as_completed(future_to_midi):\n",
    "            midi_file, snapshots_array = future.result()\n",
    "            files_as_snapshots.append((midi_file, snapshots_array))\n",
    "            progress_bar.update(1)\n",
    "            progress_bar.set_description(f\"Processed dataset ({progress_bar.n}/{progress_bar.total})\")\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    grouped_snapshots = defaultdict(dict)\n",
    "    for midi_file, snapshots_array in files_as_snapshots:\n",
    "        base_pattern = '_'.join(os.path.basename(midi_file).lower().split('_')[:-1])\n",
    "        if 'righth' in midi_file.lower():\n",
    "            grouped_snapshots[base_pattern]['rightH'] = snapshots_array\n",
    "        elif 'lefth' in midi_file.lower():\n",
    "            grouped_snapshots[base_pattern]['leftH'] = snapshots_array\n",
    "\n",
    "    final_grouped_snapshots = []\n",
    "    for group in grouped_snapshots.values():\n",
    "        if group['rightH'] is not None and group['leftH'] is not None:\n",
    "            final_grouped_snapshots.append(trim_snapshots([group['rightH'], group['leftH']]))\n",
    "\n",
    "    print(f\"Processed {len(files_as_snapshots)} of {total_files} files\")\n",
    "\n",
    "    return final_grouped_snapshots\n",
    "\n",
    "\n",
    "def filter_piano_range(grouped_snapshots):\n",
    "    \"\"\"\n",
    "    Filters the snapshots to keep only the notes in the piano range (MIDI notes 21 to 108).\n",
    "\n",
    "    Args:\n",
    "        grouped_snapshots (list): A list of lists, where each sublist contains numpy arrays of snapshots\n",
    "                                  for a group of MIDI files.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of lists, where each sublist contains numpy arrays of filtered snapshots\n",
    "              for a group of MIDI files, keeping only the piano range notes.\n",
    "    \"\"\"\n",
    "    filtered_groups = []\n",
    "\n",
    "    for group in grouped_snapshots:\n",
    "        filtered_group = []\n",
    "        for snapshots in group:\n",
    "            filtered_snapshots = [snapshot[21:109] for snapshot in snapshots]\n",
    "            filtered_group.append(np.array(filtered_snapshots))\n",
    "        filtered_groups.append(filtered_group)\n",
    "\n",
    "    return filtered_groups\n",
    "\n",
    "# Function to map MIDI note to octave position\n",
    "def map_to_octave(note):\n",
    "    return note % 12\n",
    "\n",
    "# Function to compress a single track\n",
    "def compress_track(track):\n",
    "    compressed_track = np.zeros((track.shape[0], 12))\n",
    "    for i, snapshot in enumerate(track):\n",
    "        for note_index, is_active in enumerate(snapshot):\n",
    "            if is_active:\n",
    "                octave_position = map_to_octave(note_index)\n",
    "                compressed_track[i][octave_position] = 1\n",
    "    return compressed_track\n",
    "\n",
    "def compress_dataset(dataset):\n",
    "    compressed_dataset = []\n",
    "    for song in dataset_as_snapshots:\n",
    "        compressed_song = []\n",
    "        for track in song:\n",
    "            compressed_track = compress_track(track)\n",
    "            compressed_song.append(compressed_track)\n",
    "        compressed_dataset.append(compressed_song)\n",
    "    return compressed_dataset"
   ],
   "id": "7fbd94f8a37edac8",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.2 Lade die Snapshots aus dem Midi datensatz\n",
    "\n",
    "jeder song hat: \n",
    "- zuerst die rechte hand [0]\n",
    "- dann die linke hand [1]\n"
   ],
   "id": "3ed93f64623e2635"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T14:51:04.350050Z",
     "start_time": "2024-06-17T14:50:03.536603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create snapshots\n",
    "dataset_as_snapshots = process_dataset_multithreaded(\"/home/falaxdb/Repos/Learn-ml/Transformer-pytorch/piano_data/maestro_v3/hands_split_into_seperate_midis\", 0.1)\n",
    "# filter snapshots to 88 piano notes\n",
    "dataset_as_snapshots = filter_piano_range(dataset_as_snapshots)\n",
    "# compress data into one octave\n",
    "dataset_as_snapshots = compress_dataset(dataset_as_snapshots)\n",
    "\n",
    "for song in dataset_as_snapshots:\n",
    "    print(\"song:\")\n",
    "    for track in song:\n",
    "        print(track.shape)"
   ],
   "id": "409c6c9eafcb35de",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed dataset (1038/1038): 100%|██████████| 1038/1038 [00:12<00:00, 83.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1038 of 1038 files\n",
      "song:\n",
      "(752, 12)\n",
      "(752, 12)\n",
      "song:\n",
      "(1083, 12)\n",
      "(1083, 12)\n",
      "song:\n",
      "(1432, 12)\n",
      "(1432, 12)\n",
      "song:\n",
      "(2730, 12)\n",
      "(2730, 12)\n",
      "song:\n",
      "(2220, 12)\n",
      "(2220, 12)\n",
      "song:\n",
      "(3707, 12)\n",
      "(3707, 12)\n",
      "song:\n",
      "(3479, 12)\n",
      "(3479, 12)\n",
      "song:\n",
      "(2981, 12)\n",
      "(2981, 12)\n",
      "song:\n",
      "(601, 12)\n",
      "(601, 12)\n",
      "song:\n",
      "(1837, 12)\n",
      "(1837, 12)\n",
      "song:\n",
      "(3464, 12)\n",
      "(3464, 12)\n",
      "song:\n",
      "(3805, 12)\n",
      "(3805, 12)\n",
      "song:\n",
      "(1082, 12)\n",
      "(1082, 12)\n",
      "song:\n",
      "(2604, 12)\n",
      "(2604, 12)\n",
      "song:\n",
      "(5279, 12)\n",
      "(5279, 12)\n",
      "song:\n",
      "(5764, 12)\n",
      "(5764, 12)\n",
      "song:\n",
      "(5355, 12)\n",
      "(5355, 12)\n",
      "song:\n",
      "(7677, 12)\n",
      "(7677, 12)\n",
      "song:\n",
      "(1328, 12)\n",
      "(1328, 12)\n",
      "song:\n",
      "(1926, 12)\n",
      "(1926, 12)\n",
      "song:\n",
      "(862, 12)\n",
      "(862, 12)\n",
      "song:\n",
      "(2767, 12)\n",
      "(2767, 12)\n",
      "song:\n",
      "(1778, 12)\n",
      "(1778, 12)\n",
      "song:\n",
      "(3741, 12)\n",
      "(3741, 12)\n",
      "song:\n",
      "(7862, 12)\n",
      "(7862, 12)\n",
      "song:\n",
      "(2175, 12)\n",
      "(2175, 12)\n",
      "song:\n",
      "(7165, 12)\n",
      "(7165, 12)\n",
      "song:\n",
      "(989, 12)\n",
      "(989, 12)\n",
      "song:\n",
      "(2876, 12)\n",
      "(2876, 12)\n",
      "song:\n",
      "(10855, 12)\n",
      "(10855, 12)\n",
      "song:\n",
      "(6304, 12)\n",
      "(6304, 12)\n",
      "song:\n",
      "(4344, 12)\n",
      "(4344, 12)\n",
      "song:\n",
      "(2716, 12)\n",
      "(2716, 12)\n",
      "song:\n",
      "(2461, 12)\n",
      "(2461, 12)\n",
      "song:\n",
      "(1363, 12)\n",
      "(1363, 12)\n",
      "song:\n",
      "(4738, 12)\n",
      "(4738, 12)\n",
      "song:\n",
      "(3362, 12)\n",
      "(3362, 12)\n",
      "song:\n",
      "(7533, 12)\n",
      "(7533, 12)\n",
      "song:\n",
      "(2915, 12)\n",
      "(2915, 12)\n",
      "song:\n",
      "(3410, 12)\n",
      "(3410, 12)\n",
      "song:\n",
      "(3530, 12)\n",
      "(3530, 12)\n",
      "song:\n",
      "(14334, 12)\n",
      "(14334, 12)\n",
      "song:\n",
      "(7505, 12)\n",
      "(7505, 12)\n",
      "song:\n",
      "(2677, 12)\n",
      "(2677, 12)\n",
      "song:\n",
      "(8317, 12)\n",
      "(8317, 12)\n",
      "song:\n",
      "(4823, 12)\n",
      "(4823, 12)\n",
      "song:\n",
      "(6067, 12)\n",
      "(6067, 12)\n",
      "song:\n",
      "(4252, 12)\n",
      "(4252, 12)\n",
      "song:\n",
      "(2789, 12)\n",
      "(2789, 12)\n",
      "song:\n",
      "(10531, 12)\n",
      "(10531, 12)\n",
      "song:\n",
      "(2591, 12)\n",
      "(2591, 12)\n",
      "song:\n",
      "(5096, 12)\n",
      "(5096, 12)\n",
      "song:\n",
      "(13355, 12)\n",
      "(13355, 12)\n",
      "song:\n",
      "(5088, 12)\n",
      "(5088, 12)\n",
      "song:\n",
      "(3293, 12)\n",
      "(3293, 12)\n",
      "song:\n",
      "(2539, 12)\n",
      "(2539, 12)\n",
      "song:\n",
      "(5049, 12)\n",
      "(5049, 12)\n",
      "song:\n",
      "(425, 12)\n",
      "(425, 12)\n",
      "song:\n",
      "(6178, 12)\n",
      "(6178, 12)\n",
      "song:\n",
      "(1460, 12)\n",
      "(1460, 12)\n",
      "song:\n",
      "(9465, 12)\n",
      "(9465, 12)\n",
      "song:\n",
      "(5877, 12)\n",
      "(5877, 12)\n",
      "song:\n",
      "(2077, 12)\n",
      "(2077, 12)\n",
      "song:\n",
      "(1801, 12)\n",
      "(1801, 12)\n",
      "song:\n",
      "(3488, 12)\n",
      "(3488, 12)\n",
      "song:\n",
      "(3197, 12)\n",
      "(3197, 12)\n",
      "song:\n",
      "(2758, 12)\n",
      "(2758, 12)\n",
      "song:\n",
      "(14013, 12)\n",
      "(14013, 12)\n",
      "song:\n",
      "(6414, 12)\n",
      "(6414, 12)\n",
      "song:\n",
      "(5149, 12)\n",
      "(5149, 12)\n",
      "song:\n",
      "(2439, 12)\n",
      "(2439, 12)\n",
      "song:\n",
      "(2263, 12)\n",
      "(2263, 12)\n",
      "song:\n",
      "(3950, 12)\n",
      "(3950, 12)\n",
      "song:\n",
      "(3757, 12)\n",
      "(3757, 12)\n",
      "song:\n",
      "(4853, 12)\n",
      "(4853, 12)\n",
      "song:\n",
      "(2180, 12)\n",
      "(2180, 12)\n",
      "song:\n",
      "(6346, 12)\n",
      "(6346, 12)\n",
      "song:\n",
      "(6332, 12)\n",
      "(6332, 12)\n",
      "song:\n",
      "(1783, 12)\n",
      "(1783, 12)\n",
      "song:\n",
      "(5780, 12)\n",
      "(5780, 12)\n",
      "song:\n",
      "(3736, 12)\n",
      "(3736, 12)\n",
      "song:\n",
      "(7201, 12)\n",
      "(7201, 12)\n",
      "song:\n",
      "(2480, 12)\n",
      "(2480, 12)\n",
      "song:\n",
      "(1047, 12)\n",
      "(1047, 12)\n",
      "song:\n",
      "(7208, 12)\n",
      "(7208, 12)\n",
      "song:\n",
      "(994, 12)\n",
      "(994, 12)\n",
      "song:\n",
      "(2347, 12)\n",
      "(2347, 12)\n",
      "song:\n",
      "(2961, 12)\n",
      "(2961, 12)\n",
      "song:\n",
      "(1718, 12)\n",
      "(1718, 12)\n",
      "song:\n",
      "(3237, 12)\n",
      "(3237, 12)\n",
      "song:\n",
      "(9957, 12)\n",
      "(9957, 12)\n",
      "song:\n",
      "(1375, 12)\n",
      "(1375, 12)\n",
      "song:\n",
      "(2244, 12)\n",
      "(2244, 12)\n",
      "song:\n",
      "(1751, 12)\n",
      "(1751, 12)\n",
      "song:\n",
      "(6201, 12)\n",
      "(6201, 12)\n",
      "song:\n",
      "(1741, 12)\n",
      "(1741, 12)\n",
      "song:\n",
      "(5672, 12)\n",
      "(5672, 12)\n",
      "song:\n",
      "(4515, 12)\n",
      "(4515, 12)\n",
      "song:\n",
      "(6127, 12)\n",
      "(6127, 12)\n",
      "song:\n",
      "(2460, 12)\n",
      "(2460, 12)\n",
      "song:\n",
      "(6708, 12)\n",
      "(6708, 12)\n",
      "song:\n",
      "(15143, 12)\n",
      "(15143, 12)\n",
      "song:\n",
      "(4672, 12)\n",
      "(4672, 12)\n",
      "song:\n",
      "(3197, 12)\n",
      "(3197, 12)\n",
      "song:\n",
      "(2049, 12)\n",
      "(2049, 12)\n",
      "song:\n",
      "(10910, 12)\n",
      "(10910, 12)\n",
      "song:\n",
      "(4804, 12)\n",
      "(4804, 12)\n",
      "song:\n",
      "(5526, 12)\n",
      "(5526, 12)\n",
      "song:\n",
      "(6227, 12)\n",
      "(6227, 12)\n",
      "song:\n",
      "(12817, 12)\n",
      "(12817, 12)\n",
      "song:\n",
      "(2169, 12)\n",
      "(2169, 12)\n",
      "song:\n",
      "(5360, 12)\n",
      "(5360, 12)\n",
      "song:\n",
      "(3353, 12)\n",
      "(3353, 12)\n",
      "song:\n",
      "(13946, 12)\n",
      "(13946, 12)\n",
      "song:\n",
      "(747, 12)\n",
      "(747, 12)\n",
      "song:\n",
      "(2993, 12)\n",
      "(2993, 12)\n",
      "song:\n",
      "(991, 12)\n",
      "(991, 12)\n",
      "song:\n",
      "(7959, 12)\n",
      "(7959, 12)\n",
      "song:\n",
      "(9339, 12)\n",
      "(9339, 12)\n",
      "song:\n",
      "(5180, 12)\n",
      "(5180, 12)\n",
      "song:\n",
      "(11535, 12)\n",
      "(11535, 12)\n",
      "song:\n",
      "(3338, 12)\n",
      "(3338, 12)\n",
      "song:\n",
      "(1324, 12)\n",
      "(1324, 12)\n",
      "song:\n",
      "(1690, 12)\n",
      "(1690, 12)\n",
      "song:\n",
      "(1880, 12)\n",
      "(1880, 12)\n",
      "song:\n",
      "(11391, 12)\n",
      "(11391, 12)\n",
      "song:\n",
      "(1331, 12)\n",
      "(1331, 12)\n",
      "song:\n",
      "(3748, 12)\n",
      "(3748, 12)\n",
      "song:\n",
      "(1336, 12)\n",
      "(1336, 12)\n",
      "song:\n",
      "(3835, 12)\n",
      "(3835, 12)\n",
      "song:\n",
      "(1307, 12)\n",
      "(1307, 12)\n",
      "song:\n",
      "(2385, 12)\n",
      "(2385, 12)\n",
      "song:\n",
      "(4452, 12)\n",
      "(4452, 12)\n",
      "song:\n",
      "(495, 12)\n",
      "(495, 12)\n",
      "song:\n",
      "(4154, 12)\n",
      "(4154, 12)\n",
      "song:\n",
      "(4460, 12)\n",
      "(4460, 12)\n",
      "song:\n",
      "(5519, 12)\n",
      "(5519, 12)\n",
      "song:\n",
      "(2683, 12)\n",
      "(2683, 12)\n",
      "song:\n",
      "(1884, 12)\n",
      "(1884, 12)\n",
      "song:\n",
      "(2182, 12)\n",
      "(2182, 12)\n",
      "song:\n",
      "(3413, 12)\n",
      "(3413, 12)\n",
      "song:\n",
      "(2914, 12)\n",
      "(2914, 12)\n",
      "song:\n",
      "(2086, 12)\n",
      "(2086, 12)\n",
      "song:\n",
      "(5410, 12)\n",
      "(5410, 12)\n",
      "song:\n",
      "(1802, 12)\n",
      "(1802, 12)\n",
      "song:\n",
      "(5172, 12)\n",
      "(5172, 12)\n",
      "song:\n",
      "(3277, 12)\n",
      "(3277, 12)\n",
      "song:\n",
      "(3799, 12)\n",
      "(3799, 12)\n",
      "song:\n",
      "(5370, 12)\n",
      "(5370, 12)\n",
      "song:\n",
      "(5569, 12)\n",
      "(5569, 12)\n",
      "song:\n",
      "(12614, 12)\n",
      "(12614, 12)\n",
      "song:\n",
      "(4097, 12)\n",
      "(4097, 12)\n",
      "song:\n",
      "(1791, 12)\n",
      "(1791, 12)\n",
      "song:\n",
      "(4983, 12)\n",
      "(4983, 12)\n",
      "song:\n",
      "(6748, 12)\n",
      "(6748, 12)\n",
      "song:\n",
      "(2786, 12)\n",
      "(2786, 12)\n",
      "song:\n",
      "(1222, 12)\n",
      "(1222, 12)\n",
      "song:\n",
      "(2177, 12)\n",
      "(2177, 12)\n",
      "song:\n",
      "(9815, 12)\n",
      "(9815, 12)\n",
      "song:\n",
      "(5127, 12)\n",
      "(5127, 12)\n",
      "song:\n",
      "(6188, 12)\n",
      "(6188, 12)\n",
      "song:\n",
      "(1330, 12)\n",
      "(1330, 12)\n",
      "song:\n",
      "(2926, 12)\n",
      "(2926, 12)\n",
      "song:\n",
      "(4716, 12)\n",
      "(4716, 12)\n",
      "song:\n",
      "(1446, 12)\n",
      "(1446, 12)\n",
      "song:\n",
      "(8019, 12)\n",
      "(8019, 12)\n",
      "song:\n",
      "(1854, 12)\n",
      "(1854, 12)\n",
      "song:\n",
      "(5998, 12)\n",
      "(5998, 12)\n",
      "song:\n",
      "(5642, 12)\n",
      "(5642, 12)\n",
      "song:\n",
      "(7801, 12)\n",
      "(7801, 12)\n",
      "song:\n",
      "(8824, 12)\n",
      "(8824, 12)\n",
      "song:\n",
      "(2101, 12)\n",
      "(2101, 12)\n",
      "song:\n",
      "(3382, 12)\n",
      "(3382, 12)\n",
      "song:\n",
      "(4228, 12)\n",
      "(4228, 12)\n",
      "song:\n",
      "(6173, 12)\n",
      "(6173, 12)\n",
      "song:\n",
      "(520, 12)\n",
      "(520, 12)\n",
      "song:\n",
      "(3702, 12)\n",
      "(3702, 12)\n",
      "song:\n",
      "(2235, 12)\n",
      "(2235, 12)\n",
      "song:\n",
      "(7364, 12)\n",
      "(7364, 12)\n",
      "song:\n",
      "(962, 12)\n",
      "(962, 12)\n",
      "song:\n",
      "(2341, 12)\n",
      "(2341, 12)\n",
      "song:\n",
      "(3182, 12)\n",
      "(3182, 12)\n",
      "song:\n",
      "(1638, 12)\n",
      "(1638, 12)\n",
      "song:\n",
      "(1557, 12)\n",
      "(1557, 12)\n",
      "song:\n",
      "(2459, 12)\n",
      "(2459, 12)\n",
      "song:\n",
      "(7454, 12)\n",
      "(7454, 12)\n",
      "song:\n",
      "(5215, 12)\n",
      "(5215, 12)\n",
      "song:\n",
      "(757, 12)\n",
      "(757, 12)\n",
      "song:\n",
      "(5020, 12)\n",
      "(5020, 12)\n",
      "song:\n",
      "(4385, 12)\n",
      "(4385, 12)\n",
      "song:\n",
      "(1101, 12)\n",
      "(1101, 12)\n",
      "song:\n",
      "(2116, 12)\n",
      "(2116, 12)\n",
      "song:\n",
      "(3433, 12)\n",
      "(3433, 12)\n",
      "song:\n",
      "(12611, 12)\n",
      "(12611, 12)\n",
      "song:\n",
      "(1383, 12)\n",
      "(1383, 12)\n",
      "song:\n",
      "(4420, 12)\n",
      "(4420, 12)\n",
      "song:\n",
      "(1760, 12)\n",
      "(1760, 12)\n",
      "song:\n",
      "(5374, 12)\n",
      "(5374, 12)\n",
      "song:\n",
      "(7298, 12)\n",
      "(7298, 12)\n",
      "song:\n",
      "(1538, 12)\n",
      "(1538, 12)\n",
      "song:\n",
      "(2732, 12)\n",
      "(2732, 12)\n",
      "song:\n",
      "(1932, 12)\n",
      "(1932, 12)\n",
      "song:\n",
      "(4253, 12)\n",
      "(4253, 12)\n",
      "song:\n",
      "(7127, 12)\n",
      "(7127, 12)\n",
      "song:\n",
      "(5191, 12)\n",
      "(5191, 12)\n",
      "song:\n",
      "(2671, 12)\n",
      "(2671, 12)\n",
      "song:\n",
      "(2685, 12)\n",
      "(2685, 12)\n",
      "song:\n",
      "(4024, 12)\n",
      "(4024, 12)\n",
      "song:\n",
      "(4109, 12)\n",
      "(4109, 12)\n",
      "song:\n",
      "(2570, 12)\n",
      "(2570, 12)\n",
      "song:\n",
      "(710, 12)\n",
      "(710, 12)\n",
      "song:\n",
      "(1901, 12)\n",
      "(1901, 12)\n",
      "song:\n",
      "(6473, 12)\n",
      "(6473, 12)\n",
      "song:\n",
      "(11240, 12)\n",
      "(11240, 12)\n",
      "song:\n",
      "(2190, 12)\n",
      "(2190, 12)\n",
      "song:\n",
      "(1100, 12)\n",
      "(1100, 12)\n",
      "song:\n",
      "(1302, 12)\n",
      "(1302, 12)\n",
      "song:\n",
      "(4813, 12)\n",
      "(4813, 12)\n",
      "song:\n",
      "(2158, 12)\n",
      "(2158, 12)\n",
      "song:\n",
      "(3044, 12)\n",
      "(3044, 12)\n",
      "song:\n",
      "(10285, 12)\n",
      "(10285, 12)\n",
      "song:\n",
      "(627, 12)\n",
      "(627, 12)\n",
      "song:\n",
      "(4156, 12)\n",
      "(4156, 12)\n",
      "song:\n",
      "(10097, 12)\n",
      "(10097, 12)\n",
      "song:\n",
      "(7590, 12)\n",
      "(7590, 12)\n",
      "song:\n",
      "(9082, 12)\n",
      "(9082, 12)\n",
      "song:\n",
      "(1099, 12)\n",
      "(1099, 12)\n",
      "song:\n",
      "(3010, 12)\n",
      "(3010, 12)\n",
      "song:\n",
      "(1918, 12)\n",
      "(1918, 12)\n",
      "song:\n",
      "(1596, 12)\n",
      "(1596, 12)\n",
      "song:\n",
      "(8857, 12)\n",
      "(8857, 12)\n",
      "song:\n",
      "(1631, 12)\n",
      "(1631, 12)\n",
      "song:\n",
      "(900, 12)\n",
      "(900, 12)\n",
      "song:\n",
      "(2124, 12)\n",
      "(2124, 12)\n",
      "song:\n",
      "(1752, 12)\n",
      "(1752, 12)\n",
      "song:\n",
      "(2398, 12)\n",
      "(2398, 12)\n",
      "song:\n",
      "(1263, 12)\n",
      "(1263, 12)\n",
      "song:\n",
      "(5078, 12)\n",
      "(5078, 12)\n",
      "song:\n",
      "(5776, 12)\n",
      "(5776, 12)\n",
      "song:\n",
      "(7870, 12)\n",
      "(7870, 12)\n",
      "song:\n",
      "(4902, 12)\n",
      "(4902, 12)\n",
      "song:\n",
      "(6841, 12)\n",
      "(6841, 12)\n",
      "song:\n",
      "(2191, 12)\n",
      "(2191, 12)\n",
      "song:\n",
      "(7071, 12)\n",
      "(7071, 12)\n",
      "song:\n",
      "(1200, 12)\n",
      "(1200, 12)\n",
      "song:\n",
      "(3348, 12)\n",
      "(3348, 12)\n",
      "song:\n",
      "(10745, 12)\n",
      "(10745, 12)\n",
      "song:\n",
      "(1335, 12)\n",
      "(1335, 12)\n",
      "song:\n",
      "(5309, 12)\n",
      "(5309, 12)\n",
      "song:\n",
      "(3604, 12)\n",
      "(3604, 12)\n",
      "song:\n",
      "(3940, 12)\n",
      "(3940, 12)\n",
      "song:\n",
      "(4583, 12)\n",
      "(4583, 12)\n",
      "song:\n",
      "(6554, 12)\n",
      "(6554, 12)\n",
      "song:\n",
      "(4477, 12)\n",
      "(4477, 12)\n",
      "song:\n",
      "(4859, 12)\n",
      "(4859, 12)\n",
      "song:\n",
      "(1883, 12)\n",
      "(1883, 12)\n",
      "song:\n",
      "(1836, 12)\n",
      "(1836, 12)\n",
      "song:\n",
      "(4940, 12)\n",
      "(4940, 12)\n",
      "song:\n",
      "(1512, 12)\n",
      "(1512, 12)\n",
      "song:\n",
      "(4921, 12)\n",
      "(4921, 12)\n",
      "song:\n",
      "(3293, 12)\n",
      "(3293, 12)\n",
      "song:\n",
      "(1837, 12)\n",
      "(1837, 12)\n",
      "song:\n",
      "(3990, 12)\n",
      "(3990, 12)\n",
      "song:\n",
      "(3888, 12)\n",
      "(3888, 12)\n",
      "song:\n",
      "(2083, 12)\n",
      "(2083, 12)\n",
      "song:\n",
      "(1052, 12)\n",
      "(1052, 12)\n",
      "song:\n",
      "(2131, 12)\n",
      "(2131, 12)\n",
      "song:\n",
      "(1330, 12)\n",
      "(1330, 12)\n",
      "song:\n",
      "(2522, 12)\n",
      "(2522, 12)\n",
      "song:\n",
      "(3930, 12)\n",
      "(3930, 12)\n",
      "song:\n",
      "(1140, 12)\n",
      "(1140, 12)\n",
      "song:\n",
      "(2919, 12)\n",
      "(2919, 12)\n",
      "song:\n",
      "(8598, 12)\n",
      "(8598, 12)\n",
      "song:\n",
      "(2377, 12)\n",
      "(2377, 12)\n",
      "song:\n",
      "(5376, 12)\n",
      "(5376, 12)\n",
      "song:\n",
      "(1704, 12)\n",
      "(1704, 12)\n",
      "song:\n",
      "(16062, 12)\n",
      "(16062, 12)\n",
      "song:\n",
      "(1073, 12)\n",
      "(1073, 12)\n",
      "song:\n",
      "(5331, 12)\n",
      "(5331, 12)\n",
      "song:\n",
      "(5185, 12)\n",
      "(5185, 12)\n",
      "song:\n",
      "(3379, 12)\n",
      "(3379, 12)\n",
      "song:\n",
      "(6228, 12)\n",
      "(6228, 12)\n",
      "song:\n",
      "(3283, 12)\n",
      "(3283, 12)\n",
      "song:\n",
      "(5289, 12)\n",
      "(5289, 12)\n",
      "song:\n",
      "(3848, 12)\n",
      "(3848, 12)\n",
      "song:\n",
      "(1636, 12)\n",
      "(1636, 12)\n",
      "song:\n",
      "(844, 12)\n",
      "(844, 12)\n",
      "song:\n",
      "(7264, 12)\n",
      "(7264, 12)\n",
      "song:\n",
      "(3026, 12)\n",
      "(3026, 12)\n",
      "song:\n",
      "(5132, 12)\n",
      "(5132, 12)\n",
      "song:\n",
      "(2150, 12)\n",
      "(2150, 12)\n",
      "song:\n",
      "(5019, 12)\n",
      "(5019, 12)\n",
      "song:\n",
      "(3123, 12)\n",
      "(3123, 12)\n",
      "song:\n",
      "(4042, 12)\n",
      "(4042, 12)\n",
      "song:\n",
      "(2639, 12)\n",
      "(2639, 12)\n",
      "song:\n",
      "(2224, 12)\n",
      "(2224, 12)\n",
      "song:\n",
      "(11091, 12)\n",
      "(11091, 12)\n",
      "song:\n",
      "(12655, 12)\n",
      "(12655, 12)\n",
      "song:\n",
      "(2352, 12)\n",
      "(2352, 12)\n",
      "song:\n",
      "(7385, 12)\n",
      "(7385, 12)\n",
      "song:\n",
      "(12982, 12)\n",
      "(12982, 12)\n",
      "song:\n",
      "(4728, 12)\n",
      "(4728, 12)\n",
      "song:\n",
      "(8597, 12)\n",
      "(8597, 12)\n",
      "song:\n",
      "(5626, 12)\n",
      "(5626, 12)\n",
      "song:\n",
      "(2493, 12)\n",
      "(2493, 12)\n",
      "song:\n",
      "(5526, 12)\n",
      "(5526, 12)\n",
      "song:\n",
      "(11555, 12)\n",
      "(11555, 12)\n",
      "song:\n",
      "(3174, 12)\n",
      "(3174, 12)\n",
      "song:\n",
      "(3612, 12)\n",
      "(3612, 12)\n",
      "song:\n",
      "(2575, 12)\n",
      "(2575, 12)\n",
      "song:\n",
      "(4223, 12)\n",
      "(4223, 12)\n",
      "song:\n",
      "(5001, 12)\n",
      "(5001, 12)\n",
      "song:\n",
      "(6788, 12)\n",
      "(6788, 12)\n",
      "song:\n",
      "(2212, 12)\n",
      "(2212, 12)\n",
      "song:\n",
      "(4314, 12)\n",
      "(4314, 12)\n",
      "song:\n",
      "(3182, 12)\n",
      "(3182, 12)\n",
      "song:\n",
      "(1816, 12)\n",
      "(1816, 12)\n",
      "song:\n",
      "(6225, 12)\n",
      "(6225, 12)\n",
      "song:\n",
      "(5749, 12)\n",
      "(5749, 12)\n",
      "song:\n",
      "(1832, 12)\n",
      "(1832, 12)\n",
      "song:\n",
      "(12233, 12)\n",
      "(12233, 12)\n",
      "song:\n",
      "(13069, 12)\n",
      "(13069, 12)\n",
      "song:\n",
      "(3438, 12)\n",
      "(3438, 12)\n",
      "song:\n",
      "(2394, 12)\n",
      "(2394, 12)\n",
      "song:\n",
      "(1621, 12)\n",
      "(1621, 12)\n",
      "song:\n",
      "(3785, 12)\n",
      "(3785, 12)\n",
      "song:\n",
      "(1933, 12)\n",
      "(1933, 12)\n",
      "song:\n",
      "(5117, 12)\n",
      "(5117, 12)\n",
      "song:\n",
      "(1718, 12)\n",
      "(1718, 12)\n",
      "song:\n",
      "(5218, 12)\n",
      "(5218, 12)\n",
      "song:\n",
      "(6013, 12)\n",
      "(6013, 12)\n",
      "song:\n",
      "(4061, 12)\n",
      "(4061, 12)\n",
      "song:\n",
      "(2810, 12)\n",
      "(2810, 12)\n",
      "song:\n",
      "(3799, 12)\n",
      "(3799, 12)\n",
      "song:\n",
      "(2148, 12)\n",
      "(2148, 12)\n",
      "song:\n",
      "(3899, 12)\n",
      "(3899, 12)\n",
      "song:\n",
      "(2317, 12)\n",
      "(2317, 12)\n",
      "song:\n",
      "(2624, 12)\n",
      "(2624, 12)\n",
      "song:\n",
      "(4159, 12)\n",
      "(4159, 12)\n",
      "song:\n",
      "(2836, 12)\n",
      "(2836, 12)\n",
      "song:\n",
      "(3381, 12)\n",
      "(3381, 12)\n",
      "song:\n",
      "(4052, 12)\n",
      "(4052, 12)\n",
      "song:\n",
      "(6032, 12)\n",
      "(6032, 12)\n",
      "song:\n",
      "(4397, 12)\n",
      "(4397, 12)\n",
      "song:\n",
      "(1924, 12)\n",
      "(1924, 12)\n",
      "song:\n",
      "(5183, 12)\n",
      "(5183, 12)\n",
      "song:\n",
      "(5340, 12)\n",
      "(5340, 12)\n",
      "song:\n",
      "(3666, 12)\n",
      "(3666, 12)\n",
      "song:\n",
      "(3672, 12)\n",
      "(3672, 12)\n",
      "song:\n",
      "(4240, 12)\n",
      "(4240, 12)\n",
      "song:\n",
      "(7420, 12)\n",
      "(7420, 12)\n",
      "song:\n",
      "(6965, 12)\n",
      "(6965, 12)\n",
      "song:\n",
      "(3127, 12)\n",
      "(3127, 12)\n",
      "song:\n",
      "(16069, 12)\n",
      "(16069, 12)\n",
      "song:\n",
      "(13674, 12)\n",
      "(13674, 12)\n",
      "song:\n",
      "(13379, 12)\n",
      "(13379, 12)\n",
      "song:\n",
      "(1723, 12)\n",
      "(1723, 12)\n",
      "song:\n",
      "(15972, 12)\n",
      "(15972, 12)\n",
      "song:\n",
      "(6346, 12)\n",
      "(6346, 12)\n",
      "song:\n",
      "(7467, 12)\n",
      "(7467, 12)\n",
      "song:\n",
      "(20946, 12)\n",
      "(20946, 12)\n",
      "song:\n",
      "(5076, 12)\n",
      "(5076, 12)\n",
      "song:\n",
      "(10042, 12)\n",
      "(10042, 12)\n",
      "song:\n",
      "(3471, 12)\n",
      "(3471, 12)\n",
      "song:\n",
      "(3700, 12)\n",
      "(3700, 12)\n",
      "song:\n",
      "(9456, 12)\n",
      "(9456, 12)\n",
      "song:\n",
      "(4550, 12)\n",
      "(4550, 12)\n",
      "song:\n",
      "(12884, 12)\n",
      "(12884, 12)\n",
      "song:\n",
      "(8237, 12)\n",
      "(8237, 12)\n",
      "song:\n",
      "(2461, 12)\n",
      "(2461, 12)\n",
      "song:\n",
      "(7261, 12)\n",
      "(7261, 12)\n",
      "song:\n",
      "(10199, 12)\n",
      "(10199, 12)\n",
      "song:\n",
      "(9498, 12)\n",
      "(9498, 12)\n",
      "song:\n",
      "(6347, 12)\n",
      "(6347, 12)\n",
      "song:\n",
      "(13801, 12)\n",
      "(13801, 12)\n",
      "song:\n",
      "(2171, 12)\n",
      "(2171, 12)\n",
      "song:\n",
      "(3388, 12)\n",
      "(3388, 12)\n",
      "song:\n",
      "(1741, 12)\n",
      "(1741, 12)\n",
      "song:\n",
      "(13999, 12)\n",
      "(13999, 12)\n",
      "song:\n",
      "(3402, 12)\n",
      "(3402, 12)\n",
      "song:\n",
      "(6633, 12)\n",
      "(6633, 12)\n",
      "song:\n",
      "(2664, 12)\n",
      "(2664, 12)\n",
      "song:\n",
      "(5430, 12)\n",
      "(5430, 12)\n",
      "song:\n",
      "(5263, 12)\n",
      "(5263, 12)\n",
      "song:\n",
      "(5842, 12)\n",
      "(5842, 12)\n",
      "song:\n",
      "(1898, 12)\n",
      "(1898, 12)\n",
      "song:\n",
      "(7489, 12)\n",
      "(7489, 12)\n",
      "song:\n",
      "(3263, 12)\n",
      "(3263, 12)\n",
      "song:\n",
      "(15086, 12)\n",
      "(15086, 12)\n",
      "song:\n",
      "(3116, 12)\n",
      "(3116, 12)\n",
      "song:\n",
      "(9672, 12)\n",
      "(9672, 12)\n",
      "song:\n",
      "(4760, 12)\n",
      "(4760, 12)\n",
      "song:\n",
      "(6616, 12)\n",
      "(6616, 12)\n",
      "song:\n",
      "(3372, 12)\n",
      "(3372, 12)\n",
      "song:\n",
      "(6598, 12)\n",
      "(6598, 12)\n",
      "song:\n",
      "(2583, 12)\n",
      "(2583, 12)\n",
      "song:\n",
      "(5506, 12)\n",
      "(5506, 12)\n",
      "song:\n",
      "(6199, 12)\n",
      "(6199, 12)\n",
      "song:\n",
      "(11381, 12)\n",
      "(11381, 12)\n",
      "song:\n",
      "(11163, 12)\n",
      "(11163, 12)\n",
      "song:\n",
      "(9931, 12)\n",
      "(9931, 12)\n",
      "song:\n",
      "(1348, 12)\n",
      "(1348, 12)\n",
      "song:\n",
      "(3464, 12)\n",
      "(3464, 12)\n",
      "song:\n",
      "(3020, 12)\n",
      "(3020, 12)\n",
      "song:\n",
      "(6837, 12)\n",
      "(6837, 12)\n",
      "song:\n",
      "(2309, 12)\n",
      "(2309, 12)\n",
      "song:\n",
      "(3204, 12)\n",
      "(3204, 12)\n",
      "song:\n",
      "(2430, 12)\n",
      "(2430, 12)\n",
      "song:\n",
      "(2165, 12)\n",
      "(2165, 12)\n",
      "song:\n",
      "(2942, 12)\n",
      "(2942, 12)\n",
      "song:\n",
      "(2347, 12)\n",
      "(2347, 12)\n",
      "song:\n",
      "(3107, 12)\n",
      "(3107, 12)\n",
      "song:\n",
      "(3395, 12)\n",
      "(3395, 12)\n",
      "song:\n",
      "(8312, 12)\n",
      "(8312, 12)\n",
      "song:\n",
      "(3695, 12)\n",
      "(3695, 12)\n",
      "song:\n",
      "(6999, 12)\n",
      "(6999, 12)\n",
      "song:\n",
      "(1334, 12)\n",
      "(1334, 12)\n",
      "song:\n",
      "(1305, 12)\n",
      "(1305, 12)\n",
      "song:\n",
      "(2588, 12)\n",
      "(2588, 12)\n",
      "song:\n",
      "(11950, 12)\n",
      "(11950, 12)\n",
      "song:\n",
      "(5440, 12)\n",
      "(5440, 12)\n",
      "song:\n",
      "(14082, 12)\n",
      "(14082, 12)\n",
      "song:\n",
      "(5629, 12)\n",
      "(5629, 12)\n",
      "song:\n",
      "(7052, 12)\n",
      "(7052, 12)\n",
      "song:\n",
      "(5160, 12)\n",
      "(5160, 12)\n",
      "song:\n",
      "(14018, 12)\n",
      "(14018, 12)\n",
      "song:\n",
      "(7911, 12)\n",
      "(7911, 12)\n",
      "song:\n",
      "(9686, 12)\n",
      "(9686, 12)\n",
      "song:\n",
      "(3617, 12)\n",
      "(3617, 12)\n",
      "song:\n",
      "(6034, 12)\n",
      "(6034, 12)\n",
      "song:\n",
      "(4194, 12)\n",
      "(4194, 12)\n",
      "song:\n",
      "(5098, 12)\n",
      "(5098, 12)\n",
      "song:\n",
      "(6482, 12)\n",
      "(6482, 12)\n",
      "song:\n",
      "(8037, 12)\n",
      "(8037, 12)\n",
      "song:\n",
      "(3599, 12)\n",
      "(3599, 12)\n",
      "song:\n",
      "(12028, 12)\n",
      "(12028, 12)\n",
      "song:\n",
      "(7321, 12)\n",
      "(7321, 12)\n",
      "song:\n",
      "(10040, 12)\n",
      "(10040, 12)\n",
      "song:\n",
      "(2916, 12)\n",
      "(2916, 12)\n",
      "song:\n",
      "(1947, 12)\n",
      "(1947, 12)\n",
      "song:\n",
      "(6291, 12)\n",
      "(6291, 12)\n",
      "song:\n",
      "(5298, 12)\n",
      "(5298, 12)\n",
      "song:\n",
      "(5246, 12)\n",
      "(5246, 12)\n",
      "song:\n",
      "(1672, 12)\n",
      "(1672, 12)\n",
      "song:\n",
      "(2867, 12)\n",
      "(2867, 12)\n",
      "song:\n",
      "(1570, 12)\n",
      "(1570, 12)\n",
      "song:\n",
      "(7190, 12)\n",
      "(7190, 12)\n",
      "song:\n",
      "(2027, 12)\n",
      "(2027, 12)\n",
      "song:\n",
      "(19571, 12)\n",
      "(19571, 12)\n",
      "song:\n",
      "(7000, 12)\n",
      "(7000, 12)\n",
      "song:\n",
      "(10240, 12)\n",
      "(10240, 12)\n",
      "song:\n",
      "(3155, 12)\n",
      "(3155, 12)\n",
      "song:\n",
      "(7493, 12)\n",
      "(7493, 12)\n",
      "song:\n",
      "(17021, 12)\n",
      "(17021, 12)\n",
      "song:\n",
      "(7449, 12)\n",
      "(7449, 12)\n",
      "song:\n",
      "(6917, 12)\n",
      "(6917, 12)\n",
      "song:\n",
      "(1539, 12)\n",
      "(1539, 12)\n",
      "song:\n",
      "(4523, 12)\n",
      "(4523, 12)\n",
      "song:\n",
      "(2014, 12)\n",
      "(2014, 12)\n",
      "song:\n",
      "(14786, 12)\n",
      "(14786, 12)\n",
      "song:\n",
      "(4921, 12)\n",
      "(4921, 12)\n",
      "song:\n",
      "(7670, 12)\n",
      "(7670, 12)\n",
      "song:\n",
      "(3094, 12)\n",
      "(3094, 12)\n",
      "song:\n",
      "(12972, 12)\n",
      "(12972, 12)\n",
      "song:\n",
      "(2726, 12)\n",
      "(2726, 12)\n",
      "song:\n",
      "(12549, 12)\n",
      "(12549, 12)\n",
      "song:\n",
      "(2443, 12)\n",
      "(2443, 12)\n",
      "song:\n",
      "(2404, 12)\n",
      "(2404, 12)\n",
      "song:\n",
      "(1139, 12)\n",
      "(1139, 12)\n",
      "song:\n",
      "(6367, 12)\n",
      "(6367, 12)\n",
      "song:\n",
      "(5681, 12)\n",
      "(5681, 12)\n",
      "song:\n",
      "(23974, 12)\n",
      "(23974, 12)\n",
      "song:\n",
      "(2242, 12)\n",
      "(2242, 12)\n",
      "song:\n",
      "(10637, 12)\n",
      "(10637, 12)\n",
      "song:\n",
      "(6874, 12)\n",
      "(6874, 12)\n",
      "song:\n",
      "(4553, 12)\n",
      "(4553, 12)\n",
      "song:\n",
      "(13136, 12)\n",
      "(13136, 12)\n",
      "song:\n",
      "(5334, 12)\n",
      "(5334, 12)\n",
      "song:\n",
      "(5946, 12)\n",
      "(5946, 12)\n",
      "song:\n",
      "(3950, 12)\n",
      "(3950, 12)\n",
      "song:\n",
      "(4403, 12)\n",
      "(4403, 12)\n",
      "song:\n",
      "(3516, 12)\n",
      "(3516, 12)\n",
      "song:\n",
      "(13033, 12)\n",
      "(13033, 12)\n",
      "song:\n",
      "(5721, 12)\n",
      "(5721, 12)\n",
      "song:\n",
      "(6813, 12)\n",
      "(6813, 12)\n",
      "song:\n",
      "(9013, 12)\n",
      "(9013, 12)\n",
      "song:\n",
      "(2406, 12)\n",
      "(2406, 12)\n",
      "song:\n",
      "(14427, 12)\n",
      "(14427, 12)\n",
      "song:\n",
      "(11177, 12)\n",
      "(11177, 12)\n",
      "song:\n",
      "(2232, 12)\n",
      "(2232, 12)\n",
      "song:\n",
      "(4168, 12)\n",
      "(4168, 12)\n",
      "song:\n",
      "(9162, 12)\n",
      "(9162, 12)\n",
      "song:\n",
      "(11664, 12)\n",
      "(11664, 12)\n",
      "song:\n",
      "(2101, 12)\n",
      "(2101, 12)\n",
      "song:\n",
      "(1404, 12)\n",
      "(1404, 12)\n",
      "song:\n",
      "(1889, 12)\n",
      "(1889, 12)\n",
      "song:\n",
      "(2484, 12)\n",
      "(2484, 12)\n",
      "song:\n",
      "(7482, 12)\n",
      "(7482, 12)\n",
      "song:\n",
      "(4877, 12)\n",
      "(4877, 12)\n",
      "song:\n",
      "(14479, 12)\n",
      "(14479, 12)\n",
      "song:\n",
      "(2073, 12)\n",
      "(2073, 12)\n",
      "song:\n",
      "(2711, 12)\n",
      "(2711, 12)\n",
      "song:\n",
      "(5057, 12)\n",
      "(5057, 12)\n",
      "song:\n",
      "(4321, 12)\n",
      "(4321, 12)\n",
      "song:\n",
      "(4643, 12)\n",
      "(4643, 12)\n",
      "song:\n",
      "(4518, 12)\n",
      "(4518, 12)\n",
      "song:\n",
      "(4960, 12)\n",
      "(4960, 12)\n",
      "song:\n",
      "(1517, 12)\n",
      "(1517, 12)\n",
      "song:\n",
      "(7537, 12)\n",
      "(7537, 12)\n",
      "song:\n",
      "(4652, 12)\n",
      "(4652, 12)\n",
      "song:\n",
      "(4628, 12)\n",
      "(4628, 12)\n",
      "song:\n",
      "(14409, 12)\n",
      "(14409, 12)\n",
      "song:\n",
      "(5468, 12)\n",
      "(5468, 12)\n",
      "song:\n",
      "(7807, 12)\n",
      "(7807, 12)\n",
      "song:\n",
      "(6849, 12)\n",
      "(6849, 12)\n",
      "song:\n",
      "(8716, 12)\n",
      "(8716, 12)\n",
      "song:\n",
      "(7044, 12)\n",
      "(7044, 12)\n",
      "song:\n",
      "(19759, 12)\n",
      "(19759, 12)\n",
      "song:\n",
      "(20955, 12)\n",
      "(20955, 12)\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The 88 Keys are now compressed into one oktave 12 keys",
   "id": "c3bd983d02358436"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.3 Daten Batchen, aufteilen und in Richtigen Dataloader packen",
   "id": "2f1a03da39cf1cf4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T14:51:04.353453Z",
     "start_time": "2024-06-17T14:51:04.351033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SOS und EOS Tokens definieren\n",
    "\n",
    "# Define SOS and EOS tokens as global variables\n",
    "SOS_TOKEN = np.full((1, 12), 2)  # SOS token representation with 2\n",
    "EOS_TOKEN = np.full((1, 12), 3)  # EOS token representation with 3\n",
    "\n",
    "UNK_IDX = 5 #Brauchen wir glaube ich nicht\n",
    "PAD_IDX = 4 #Brauchen wir auch nicht, weil die sequenzen alle genau richtig lang sind"
   ],
   "id": "1a8cf5d825cfcc6a",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T14:51:05.056032Z",
     "start_time": "2024-06-17T14:51:04.354570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Function to add SOS and EOS tokens to each chunk\n",
    "def add_sos_eos_to_chunks(chunks):\n",
    "    new_chunks = []\n",
    "    for chunk in chunks:\n",
    "        new_chunk = np.vstack([SOS_TOKEN, chunk, EOS_TOKEN])\n",
    "        new_chunks.append(new_chunk)\n",
    "    return new_chunks\n",
    "\n",
    "# Function to split sequences into chunks\n",
    "def split_into_chunks(sequence, chunk_size):\n",
    "    return [sequence[i:i + chunk_size] for i in range(0, len(sequence), chunk_size)]\n",
    "\n",
    "# Function to filter out short chunks while maintaining pairs\n",
    "def filter_short_chunks(chunks_1, chunks_2, min_length):\n",
    "    filtered_chunks_1 = []\n",
    "    filtered_chunks_2 = []\n",
    "    for chunk_1, chunk_2 in zip(chunks_1, chunks_2):\n",
    "        if len(chunk_1) >= min_length and len(chunk_2) >= min_length:\n",
    "            filtered_chunks_1.append(chunk_1)\n",
    "            filtered_chunks_2.append(chunk_2)\n",
    "    return filtered_chunks_1, filtered_chunks_2\n",
    "\n",
    "# Custom Dataset class\n",
    "class PianoDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.data[idx]\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Prepare the dataset with paired sequences and SOS/EOS tokens for each chunk\n",
    "def prepare_dataset(dataset_as_snapshots, chunk_size, min_length):\n",
    "    data = []\n",
    "    for song in dataset_as_snapshots:\n",
    "        track_1, track_2 = song\n",
    "        assert len(track_1) == len(track_2), \"Tracks must have the same length\"\n",
    "        \n",
    "        chunks_1 = split_into_chunks(track_1, chunk_size)\n",
    "        chunks_2 = split_into_chunks(track_2, chunk_size)\n",
    "        chunks_1, chunks_2 = filter_short_chunks(chunks_1, chunks_2, min_length)\n",
    "        \n",
    "        # Add SOS and EOS tokens to each chunk\n",
    "        chunks_1 = add_sos_eos_to_chunks(chunks_1)\n",
    "        chunks_2 = add_sos_eos_to_chunks(chunks_2)\n",
    "        \n",
    "        for x, y in zip(chunks_1, chunks_2):\n",
    "            data.append((x, y))\n",
    "    return data\n",
    "\n",
    "# Define your dataset parameters\n",
    "chunk_size = 50  # Define the chunk size you want\n",
    "min_length = chunk_size  # Minimum length to keep a chunk\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Prepare the dataset\n",
    "data = prepare_dataset(dataset_as_snapshots, chunk_size, min_length)\n",
    "\n",
    "# Split the dataset using sklearn while maintaining pairs\n",
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42, shuffle=True)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "# Create custom datasets\n",
    "train_dataset = PianoDataset(train_data)\n",
    "val_dataset = PianoDataset(val_data)\n",
    "test_dataset = PianoDataset(test_data)\n",
    "\n",
    "# Create DataLoaders for each subset with drop_last=True\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "# Iterate over the DataLoader (example with train_loader)\n",
    "for batch in train_loader:\n",
    "    X, y = batch\n",
    "    print(X.shape, y.shape)\n",
    "    # X and y should both have shape (batch_size, chunk_size + 2, 88) because of SOS and EOS tokens\n"
   ],
   "id": "ededfd5b09434ff3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n",
      "torch.Size([32, 52, 12]) torch.Size([32, 52, 12])\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "1. **Splitting and Filtering Chunks**:\n",
    "   - The `split_into_chunks` function splits each sequence into fixed-length chunks.\n",
    "   - The `filter_short_chunks` function ensures that only pairs of chunks (from `src` and `tgt`) that both meet the minimum length requirement are kept. This maintains the alignment of the sequences.\n",
    "\n",
    "2. **Preparing the Dataset**:\n",
    "   - The `prepare_dataset` function processes each song, splits the tracks into chunks, and applies the filtering function to ensure that the chunks are correctly paired.\n",
    "\n",
    "3. **Creating the Datasets**:\n",
    "   - The data is split into training, validation, and test sets using `train_test_split` from `sklearn`, ensuring that the pairs are maintained.\n",
    "\n",
    "4. **Creating the DataLoaders**:\n",
    "   - DataLoaders are created for each subset with `drop_last=True` to ensure that only complete batches are processed.\n",
    "\n",
    "By following this approach, the original alignment between `src` and `tgt` sequences is preserved, ensuring that the data is correctly prepared for training your Transformer model."
   ],
   "id": "f5344c7640278043"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Explenation Batch iteration\n",
    "\n",
    "The line `X, y = batch` is unpacking the batch of data retrieved from the DataLoader into two variables, `X` and `y`. Here’s a detailed explanation of what happens at this line:\n",
    "\n",
    "### Explanation of `X, y = batch`\n",
    "\n",
    "1. **DataLoader Output**:\n",
    "   - When you iterate over a DataLoader in PyTorch, it yields batches of data. Each batch is typically a tuple containing the inputs and the targets (labels) for a single batch.\n",
    "   - In this specific context, each batch contains pairs of sequences: `X` (the source sequence) and `y` (the target sequence).\n",
    "\n",
    "2. **Batch Structure**:\n",
    "   - In the `PianoDataset` class, the `__getitem__` method returns a tuple `(x, y)`, where `x` is a tensor representing the input sequence and `y` is a tensor representing the corresponding target sequence.\n",
    "   - The DataLoader combines these tuples into a single batch. Therefore, a batch is a tuple containing two tensors: one for all the input sequences in the batch and one for all the target sequences in the batch.\n",
    "\n",
    "3. **Unpacking the Batch**:\n",
    "   - The line `X, y = batch` is unpacking the batch into two separate variables: `X` for the input sequences and `y` for the target sequences.\n",
    "   - If `batch` is a tuple of two tensors, `X` and `y` will be assigned the values of these two tensors, respectively.\n",
    "\n",
    "4. **Shape of `X` and `y`**:\n",
    "   - After unpacking, `X` and `y` will both have the shape `(batch_size, chunk_size, 88)`, where:\n",
    "     - `batch_size` is the number of sequences in the batch (in this case, 16).\n",
    "     - `chunk_size` is the length of each sequence (in this case, 512).\n",
    "     - `88` is the number of features (in this case, representing the 88 keys of a piano).\n",
    "\n",
    "### Example\n",
    "\n",
    "Here’s a simplified example to illustrate the concept:\n",
    "\n",
    "```python\n",
    "# Assume each element in the dataset is a tuple (x, y)\n",
    "# Example data with 2 elements, where each element is a tuple of two sequences\n",
    "example_data = [\n",
    "    (torch.ones(512, 88), torch.zeros(512, 88)),\n",
    "    (torch.ones(512, 88) * 2, torch.zeros(512, 88) * 2)\n",
    "]\n",
    "\n",
    "# Create a DataLoader\n",
    "example_loader = DataLoader(example_data, batch_size=2)\n",
    "\n",
    "# Iterate over the DataLoader\n",
    "for batch in example_loader:\n",
    "    X, y = batch  # Unpack the batch into X (inputs) and y (targets)\n",
    "    print(\"X:\", X)\n",
    "    print(\"y:\", y)\n",
    "```\n",
    "\n",
    "In this example, `batch` would be a tuple containing two tensors, each of shape `(2, 512, 88)` (since `batch_size=2`). The line `X, y = batch` unpacks these tensors into `X` and `y` for further processing.\n",
    "\n",
    "By using this approach, you can easily access the input and target sequences separately within each batch, facilitating their use in training or evaluation loops."
   ],
   "id": "2d5d71e861f9227a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Modell definieren",
   "id": "87f7038bbc5e3968"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 Positional Encoding",
   "id": "6a0e9371d631bd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T14:51:05.062126Z",
     "start_time": "2024-06-17T14:51:05.057210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    r\"\"\"Inject some information about the relative or absolute position of the tokens in the sequence.\n",
    "        The positional encodings have the same dimension as the embeddings, so that the two can be summed.\n",
    "        Here, we use sine and cosine functions of different frequencies.\n",
    "    .. math:\n",
    "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
    "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
    "        \\text{where pos is the word position and i is the embed idx)\n",
    "    Args:\n",
    "        d_model: the embed dim (required).\n",
    "        dropout: the dropout value (default=0.1).\n",
    "        max_len: the max. length of the incoming sequence (default=5000).\n",
    "    Examples:\n",
    "        >>> pos_encoder = PositionalEncoding(d_model)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        # Info\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Encoding - From formula -> This is basically applying the formula for Positional encoding (The one with Sinus and Cosinus)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1) # Baically a positions list 0, 1, 2, 3, 4, 5, ...\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # 1000^(2i/dim_model)\n",
    "        \n",
    "        # # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        \n",
    "        #  # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "         # Saving buffer (same as parameter without gradients needed)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r\"\"\"Inputs of forward function\n",
    "        Args:\n",
    "            x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        Examples:\n",
    "            >>> output = pos_encoder(x)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Residual connection + pos encoding\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ],
   "id": "5baa47ca2c6fc5fe",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 Transformer definieren",
   "id": "257b2f3b1559ade8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "TODO: Am schluss wahrscheinlichkeiten für jedes feature in einem Token noch ausgeben",
   "id": "ab19ba674d7481d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T14:51:05.078488Z",
     "start_time": "2024-06-17T14:51:05.063107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        # Hier werden glaube ich die Layer definiert. Ist Im guide glaube ich in anderer Reihenfolge -> hab sie jetzt in die gleiche Reihenfolge wie im guide gepackt\n",
    "        \n",
    "        ## Layers des Gesamten Modells\n",
    "        \n",
    "        # Positional Encoding zur Hinzufügung von Positionsinformationen zu den Token-Einbettungen\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
    "        \n",
    "        # Token-Einbettung für Quell- und Zielvokabular\n",
    "        # I use a nn.Embedding instead of the self defined TokenEmbedding\n",
    "        # brauche ich evtl nicht, da die Daten ja schon quasi \"embedded\" sind\n",
    "        #self.src_tok_emb = nn.Embedding(src_vocab_size, emb_size) \n",
    "        #self.tgt_tok_emb = nn.Embedding(tgt_vocab_size, emb_size)\n",
    "        \n",
    "        # Initialisierung des nn.Transformer Moduls mit den gegebenen Hyperparametern\n",
    "        self.transformer = nn.Transformer(d_model=emb_size,\n",
    "                                          nhead=nhead,\n",
    "                                          num_encoder_layers=num_encoder_layers,\n",
    "                                          num_decoder_layers=num_decoder_layers,\n",
    "                                          dim_feedforward=dim_feedforward,\n",
    "                                          dropout=dropout,\n",
    "                                          batch_first=True)\n",
    "        \n",
    "        # Linearer Layer zur Projektion der Ausgabedimensionen auf die Zielvokabulargröße\n",
    "        # Generator ist also glaube ich die Outputlayer, die die Ausgabe in die Wahrscheinlichkeiten für die einzelnen Tokens übersetzt\n",
    "        \n",
    "        # hier Wichtig, bin mir nicht sicher, was hier gelten soll: \n",
    "        # ich glaube 88 ist richtig. muss mir aber noch anschauen, was genau hier passiert\n",
    "        self.generator = nn.Linear(emb_size, 12)  # Output should match the number of piano keys \n",
    "        # self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                # src_mask: Tensor,\n",
    "                tgt_mask=None,\n",
    "                src_padding_mask=None,\n",
    "                tgt_padding_mask=None):\n",
    "        \n",
    "        \n",
    "        # Einbettung und Positional Encoding für die Quellsequenz\n",
    "        #src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        src_emb = self.positional_encoding(src)\n",
    "        \n",
    "        # Einbettung und Positional Encoding für die Zielsequenz\n",
    "        #tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        tgt_emb = self.positional_encoding(trg)\n",
    "        \n",
    "        # Hier bin ich noch etwas verwirrt, warum die dimensionen Permutiert werden müssen\n",
    "        # Aus der Erklärung für die batch_first variable von nn.Transformer:\n",
    "        # If True, then the input and output tensors are provided as (batch, seq, feature). Default: False (seq, batch, feature).\n",
    "        \n",
    "        # (deprecated) src_emb = src_emb.permute(1,0,2)\n",
    "        # (deprecated) tgt_emb = tgt_emb.permute(1,0,2)\n",
    "        #print(\"src_emb shape:\", src_emb.shape)\n",
    "        #print(\"tgt_emb shape:\", tgt_emb.shape)\n",
    "        \n",
    "        # Durchführen der Transformationsoperation\n",
    "        # src_emb und tgt_emb sind die eingebetteten Sequenzen mit Positionsinformationen\n",
    "        # src_mask und tgt_mask sind die Masken, die verhindern, dass zukünftige Tokens betrachtet werden\n",
    "        # src_padding_mask, tgt_padding_mask und memory_key_padding_mask sind die Masken für Padding-Tokens\n",
    "        outs = self.transformer(src_emb, tgt_emb, tgt_mask=tgt_mask, src_key_padding_mask=src_padding_mask, tgt_key_padding_mask=tgt_padding_mask)\n",
    "        \n",
    "        # Projektion der Ausgabe auf die Zielvokabulargröße\n",
    "        return self.generator(outs)"
   ],
   "id": "48abfa2135adc5e8",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.3 Masken definieren",
   "id": "f7d6bcbbbae5a237"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T14:51:05.088083Z",
     "start_time": "2024-06-17T14:51:05.079437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    \n",
    "    # EX for size=5:\n",
    "    # [[0., -inf, -inf, -inf, -inf],\n",
    "    #  [0.,   0., -inf, -inf, -inf],\n",
    "    #  [0.,   0.,   0., -inf, -inf],\n",
    "    #  [0.,   0.,   0.,   0., -inf],\n",
    "    #  [0.,   0.,   0.,   0.,   0.]]\n",
    "    \n",
    "    return mask\n",
    "\n",
    "# Die Funktion create_mask erstellt sowohl Quell- als auch Ziel-Pad-Masken, indem sie prüft, ob Elemente in der Quell- und Zielsequenz gleich dem Pad-Token sind. Diese Masken werden transponiert, um die richtige Dimension zu erhalten.\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ],
   "id": "8f4adc50ab23f66d",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ?.? Embeddings erstellen\n",
    "\n",
    "nn.Embedding modul von pytorch wird evtl nicht benötigt.\n",
    "\n",
    "Aus chat GPT:\n",
    "\n",
    "- Die Eingabesequenzen (src) und die Zielsequenzen (tgt) haben die Form (batch_size, seq_len, feature_dim), was in Ihrem Fall (batch_size, 100, 88) ist.\n",
    "- Das positional embedding wird trotzdem benötigt\n",
    "- Da die Eingabedaten bereits in einer geeigneten Form vorliegen (dichte Vektoren), benötigen Sie kein nn.Embedding Modul. Sie können direkt die Sequenzen und Positional Encodings verwenden."
   ],
   "id": "f31a783e48c2cc12"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Training/Validation definieren",
   "id": "3203525cd895548f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.1 Hyperparameter festlegen",
   "id": "c7dc325becfbcf39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T14:51:05.097806Z",
     "start_time": "2024-06-17T14:51:05.089297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SRC_VOCAB_SIZE = 4 # Ist glaube ich das num_tokens aus dem Guide (Also wie viele Verschiedene Tokens es insgesamt gibt\n",
    "TGT_VOCAB_SIZE = 4 # Auch 4, da die eingabe und zielsequenz die Gleichen möglichkeiten für Tokens haben\n",
    "EMB_SIZE = 12 #die Dimesnion des Modells Die anzahl der Erwarteten features der inputs/outputs also quasi die anzahl der Wörter in einer sequenz glaube ich -> also 8 bei uns (hier werden die spezial-tokens nicht gezählt ?)\n",
    "NHEAD = 4 # Anzahl der heads in einem Attention block\n",
    "FFN_HID_DIM = 512 # Anzahl der hidden layers des Feed-forward networks \n",
    "BATCH_SIZE = 32 # wird nicht ans Modell weitergegeben. evtl für uns nicht wichtig, weil wir die Daten schon gebatcht haben?\n",
    "NUM_ENCODER_LAYERS = 4 # wie viele Encoder blöcke\n",
    "NUM_DECODER_LAYERS = 4 # wie viele Decoder Blöcke"
   ],
   "id": "481044c71e2911c3",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.2 Modell initialisieren",
   "id": "c4681d35daa933b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T14:51:05.140644Z",
     "start_time": "2024-06-17T14:51:05.099308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Modell initialisiern\n",
    "transformer = Transformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "# auf GPU laden\n",
    "transformer = transformer.to(DEVICE)\n",
    "# Kostenfunktion als CrossEntropyLoss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# Optimizer als Adam optimizer festlegen\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ],
   "id": "b8024c8f1cefe77f",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.3 Trainingsloop definieren",
   "id": "8bea243e08455c4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T14:51:05.145267Z",
     "start_time": "2024-06-17T14:51:05.141914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_loop(model, opt, loss_fn, dataloader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        X, y = batch\n",
    "        #print(X.shape, y.shape)\n",
    "        # X and y should both have shape (batch_size, chunk_size + 2, 88) because of SOS and EOS tokens\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
    "        y_input = y[:,:-1]\n",
    "        y_expected = y[:,1:]\n",
    "        \n",
    "        #print(\"Training: X shape:\", X.shape)\n",
    "        #print(\"Training: y_input shape:\", y_input.shape)\n",
    "        #print(\"Training: y_expected shape:\", y_expected.shape)\n",
    "        \n",
    "        # Get mask to mask out the next words\n",
    "        sequence_length = y_input.size(1)\n",
    "        tgt_mask = generate_square_subsequent_mask(sequence_length).to(DEVICE)\n",
    "\n",
    "        # Standard training except we pass in y_input and tgt_mask\n",
    "        logits = model(X, y_input, tgt_mask)\n",
    "        \n",
    "        #print(\"Training: prediction (model output) shape:\", logits.shape)\n",
    "        \n",
    "        #(deprecated) Permute pred to have batch size first again\n",
    "        #(deprecated) pred = pred.permute(1, 2, 0)\n",
    "        # logits ist die Ausgabe des modells, y_expected ist die erwartete ausgabe\n",
    "        # Die dimensionen müssen verändert werden, da die loss funktion die Tensoren in anderer Form erwartet\n",
    "        \n",
    "        \n",
    "        # Reshape logits and y_expected for loss calculation\n",
    "        #logits = logits.reshape(-1, logits.shape[-1])\n",
    "        #y_expected = y_expected.reshape(-1, y_expected.shape[-1])\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(logits, y_expected)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "        total_loss += loss.detach().item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ],
   "id": "374220b7c4917510",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.4 Validation loop definieren",
   "id": "1cb16d91be65f248"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T14:51:05.154244Z",
     "start_time": "2024-06-17T14:51:05.146308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validation_loop(model, loss_fn, dataloader):\n",
    "    \n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X, y = batch\n",
    "            #print(X.shape, y.shape)\n",
    "            # X and y should both have shape (batch_size, chunk_size + 2, 88) because of SOS and EOS tokens\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "            # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
    "            y_input = y[:,:-1]\n",
    "            y_expected = y[:,1:]\n",
    "            \n",
    "            # Get mask to mask out the next words\n",
    "            sequence_length = y_input.size(1)\n",
    "            tgt_mask = generate_square_subsequent_mask(sequence_length).to(DEVICE)\n",
    "\n",
    "            # Standard training except we pass in y_input and src_mask\n",
    "            logits = model(X, y_input, tgt_mask)\n",
    "\n",
    "            # Permute pred to have batch size first again\n",
    "            #pred = pred.permute(1, 2, 0)\n",
    "            # logits ist die Ausgabe des modells, y_expected ist die erwartete ausgabe\n",
    "            \n",
    "            # Reshape logits and y_expected for loss calculation\n",
    "            #logits = logits.reshape(-1, logits.shape[-1])\n",
    "            #y_expected = y_expected.reshape(-1, y_expected.shape[-1])\n",
    "            \n",
    "            # Calculate the loss\n",
    "            loss = loss_fn(logits, y_expected)\n",
    "    \n",
    "            # Calculate the loss\n",
    "            loss = loss_fn(logits, y_expected)\n",
    "            total_loss += loss.detach().item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ],
   "id": "e2644c1791731b63",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Modell Trainieren",
   "id": "32d3631ed0fb71e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T14:56:29.002752Z",
     "start_time": "2024-06-17T14:51:19.861503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_loop(transformer, optimizer, loss_fn, train_loader)\n",
    "    end_time = timer()\n",
    "    val_loss = validation_loop(transformer, loss_fn, val_loader)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
   ],
   "id": "e7fe3fe6e90de130",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 23.955, Val loss: 22.582, Epoch time = 28.909s\n",
      "Epoch: 2, Train loss: 23.001, Val loss: 21.884, Epoch time = 25.087s\n",
      "Epoch: 3, Train loss: 22.615, Val loss: 21.924, Epoch time = 22.149s\n",
      "Epoch: 4, Train loss: 22.366, Val loss: 22.307, Epoch time = 28.447s\n",
      "Epoch: 5, Train loss: 22.174, Val loss: 22.570, Epoch time = 21.637s\n",
      "Epoch: 6, Train loss: 22.021, Val loss: 23.383, Epoch time = 38.738s\n",
      "Epoch: 7, Train loss: 21.898, Val loss: 23.530, Epoch time = 37.196s\n",
      "Epoch: 8, Train loss: 21.772, Val loss: 24.818, Epoch time = 28.882s\n",
      "Epoch: 9, Train loss: 21.668, Val loss: 24.724, Epoch time = 28.047s\n",
      "Epoch: 10, Train loss: 21.569, Val loss: 25.542, Epoch time = 40.845s\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Inferenz",
   "id": "a4ab2907222264af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T15:08:02.978525Z",
     "start_time": "2024-06-17T15:08:02.970005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict(model, input_sequence, max_length, start_token, end_token, device):\n",
    "    model.eval()\n",
    "    \n",
    "    # Prepare input sequence (add batch dimension if necessary and move to device)\n",
    "    if input_sequence.dim() == 2:  # if shape is [seq_len, num_features]\n",
    "        input_sequence = input_sequence.unsqueeze(0)  # add batch dimension\n",
    "    \n",
    "    input_sequence = input_sequence.to(device)  # move to device\n",
    "    #print(\"Input Melody:\", input_sequence.shape)\n",
    "    #print(\"=====================\")\n",
    "    \n",
    "    # Prepare start token for target sequence\n",
    "    y_input = torch.tensor(start_token, dtype=torch.float, device=device).unsqueeze(0)  # shape: [1, 1, 12]\n",
    "    #print(\"y_input:\", y_input.shape)\n",
    "    #print(\"=================\")\n",
    "    \n",
    "    prediction_tensor_list =[]\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        # Get target mask\n",
    "        tgt_mask = generate_square_subsequent_mask(y_input.size(1)).to(device)\n",
    "        \n",
    "        # Perform prediction\n",
    "        pred = model(input_sequence, y_input, tgt_mask)\n",
    "        \n",
    "        prediction_tensor_list.append(pred)\n",
    "        \n",
    "        # Apply a threshold to convert logits to binary values\n",
    "        next_item = (pred[:, -1, :] > 0).float().unsqueeze(1)  # Shape: [1, 1, num_features]\n",
    "        \n",
    "        # Concatenate previous input with predicted token\n",
    "        y_input = torch.cat((y_input, next_item), dim=1)\n",
    "        \n",
    "        # Stop if model predicts end of sequence\n",
    "        if torch.equal(next_item.squeeze(), torch.tensor(end_token, dtype=torch.float, device=device).squeeze()):\n",
    "            #print(\"end token found\")\n",
    "            break\n",
    "    \n",
    "    return y_input.squeeze(0).tolist(), prediction_tensor_list  # Remove batch dimension"
   ],
   "id": "26bc4ea14903c90a",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T15:13:26.922768Z",
     "start_time": "2024-06-17T15:13:26.428622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch in test_loader:\n",
    "    X, y = batch\n",
    "    X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "    \n",
    "    melody = X[0]\n",
    "    real_harmony = y[0]\n",
    "    \n",
    "    \n",
    "    prediction, prediction_tensor_list = predict(transformer, melody, 100, SOS_TOKEN, EOS_TOKEN, DEVICE)\n",
    "    \n",
    "    #print(\"Prediction:\", prediction)\n",
    "    #print(\"=====================\")\n",
    "    #print(\"real harmony:\", real_harmony)\n",
    "    \n",
    "    #prediction_tensor_list = [item for sublist in prediction_tensor_list for item in sublist]\n",
    "    max_values = []\n",
    "    min_values = []\n",
    "    \n",
    "    \n",
    "    # print(\"prediciton tensor list:\", prediction_tensor_list)\n",
    "    for tensor in prediction_tensor_list:\n",
    "        max_values.append(torch.max(tensor))\n",
    "        min_values.append(torch.min(tensor))\n",
    "    \n",
    "    print(\"max value of all tensors:\", max(max_values))\n",
    "    print(\"min value of all tensors:\", min(min_values))\n",
    "    \n",
    "    break"
   ],
   "id": "ed1ef0866a4b2012",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max value of all tensors: tensor(1.1042, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "min value of all tensors: tensor(-0.7189, device='cuda:0', grad_fn=<MinBackward1>)\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Output passt nicht wirklich. ich muss mir nohcmal anschauen, wie ich das modell am besten trainieren kann und wie man den Output am besten nochmal macht.",
   "id": "7f7180919d2e7ac2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T15:17:16.285872Z",
     "start_time": "2024-06-17T15:17:16.278487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def printHeatmap(predicted_harmony, center=0.2, vmin=0, vmax=0.4):\n",
    "    # Create the 'pictures' directory if it doesn't exist\n",
    "    if not os.path.exists('pictures'):\n",
    "        os.makedirs('pictures')\n",
    "\n",
    "    # Determine the next prefix number for saving files\n",
    "    existing_files = [f for f in os.listdir('pictures') if f.endswith('.png')]\n",
    "    if existing_files:\n",
    "        latest_file = max(existing_files)\n",
    "        latest_prefix = int(latest_file.split('_')[0])\n",
    "        prefix = f\"{latest_prefix + 1:02d}_\"\n",
    "    else:\n",
    "        prefix = \"00_\"\n",
    "\n",
    "    # Create and save a heatmap of Predicted Harmony Data\n",
    "    plt.figure(figsize=(20, 10))  # Adjust the size as necessary\n",
    "    sns.heatmap(predicted_harmony, cmap='coolwarm', center=center, vmin=vmin, vmax=vmax)  # Adjust color map and limits based on your data\n",
    "    plt.title('Heatmap of Predicted Harmony Data')\n",
    "    plt.xlabel('Keys on piano')\n",
    "    plt.ylabel('Probability of pressing (One-Hot-Encoding)')\n",
    "    plt.savefig(os.path.join('pictures', f'{prefix}heatmap_predicted_harmony.png'))\n",
    "    plt.show()"
   ],
   "id": "ba06c1cc041145ba",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T15:19:00.789401Z",
     "start_time": "2024-06-17T15:19:00.313391Z"
    }
   },
   "cell_type": "code",
   "source": "printHeatmap(prediction, 0, -0.7, 1.1)",
   "id": "ec6441e3cd44266a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 62
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
