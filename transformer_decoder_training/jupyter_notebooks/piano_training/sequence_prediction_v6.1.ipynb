{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test of the new data preperation function",
   "id": "47a3cff2f46846ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Get data",
   "id": "6c38117c3975ef00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T21:31:43.567652Z",
     "start_time": "2024-07-21T21:31:42.742219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ],
   "id": "31d9023ac23c4ab9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T21:31:43.595745Z",
     "start_time": "2024-07-21T21:31:43.568694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if GPU is available, set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
   ],
   "id": "d6701eb5462d0966",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T21:31:43.733486Z",
     "start_time": "2024-07-21T21:31:43.596357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sos_token = np.full((1, 24), 1)\n",
    "pad_token = np.full((1, 24), 2)\n",
    "pad_token = torch.tensor(pad_token, device=device)\n",
    "\n",
    "dataset_dir = \"/home/falaxdb/Repos/minus1/datasets/maestro_v3_split/hands_split_into_seperate_midis\"\n",
    "snapshot_intervall = 0.05\n",
    "\n",
    "# Define other parameters\n",
    "batch_size = 64\n",
    "seq_length = 512\n",
    "stride = 256\n",
    "\n",
    "test_size=0.3"
   ],
   "id": "369c1b18806f37fd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T21:32:35.221048Z",
     "start_time": "2024-07-21T21:31:43.734410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformer_decoder_training.dataprep_transformer.prepare_dataloader_complete import prepare_dataset_as_dataloaders\n",
    "\n",
    "# Load Data\n",
    "\n",
    "train_loader, val_loader, test_loader = prepare_dataset_as_dataloaders(dataset_dir, snapshot_intervall, batch_size, seq_length, stride, test_size, sos_token)"
   ],
   "id": "d8b38fd9d94f89b0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed dataset (1038/1038): 100%|██████████| 1038/1038 [00:14<00:00, 72.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1038 of 1038 files\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# initialize model",
   "id": "b77930f6c1402076"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T21:32:35.223959Z",
     "start_time": "2024-07-21T21:32:35.221734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set parameters\n",
    "# Learning rate for the optimizer\n",
    "learning_rate = 1e-3\n",
    "# Number of epochs for training\n",
    "nepochs = 20\n",
    "# Embedding Size\n",
    "hidden_size = 256\n",
    "# Number of transformer blocks\n",
    "num_layers = 8\n",
    "# MultiheadAttention Heads\n",
    "num_heads = 8"
   ],
   "id": "9afd2d2d295c59f0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T21:32:35.582143Z",
     "start_time": "2024-07-21T21:32:35.224415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformer_decoder_training.models.transformer_decoder_2 import Transformer\n",
    "\n",
    "model = Transformer(num_emb=24, num_layers=num_layers, hidden_size=hidden_size, num_heads=num_heads).to(device)\n",
    "\n",
    "# Initialize the optimizer with above parameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the loss function\n",
    "# loss function should be one that can handle multi one hot encoded vectors\n",
    "# Klammern nicht vergessen\n",
    "# Chat gpt says BCEWithLogitsLoss is more stable\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ],
   "id": "ad6b8feefffc8864",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T21:49:08.120236Z",
     "start_time": "2024-07-21T21:32:35.582656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from timeit import default_timer as timer\n",
    "from transformer_decoder_training.training import training_1\n",
    "\n",
    "NUM_EPOCHS = 21\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = training_1.train_loop(model, optimizer, loss_fn, train_loader, pad_token, device)\n",
    "    end_time = timer()\n",
    "    val_loss = training_1.validation_loop(model, loss_fn, val_loader, pad_token, device)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
   ],
   "id": "e2d897672496cc9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 0.191, Val loss: 0.129, Epoch time = 44.787s\n",
      "Epoch: 2, Train loss: 0.127, Val loss: 0.125, Epoch time = 44.757s\n",
      "Epoch: 3, Train loss: 0.123, Val loss: 0.122, Epoch time = 44.990s\n",
      "Epoch: 4, Train loss: 0.120, Val loss: 0.120, Epoch time = 44.925s\n",
      "Epoch: 5, Train loss: 0.118, Val loss: 0.118, Epoch time = 45.111s\n",
      "Epoch: 6, Train loss: 0.117, Val loss: 0.117, Epoch time = 44.873s\n",
      "Epoch: 7, Train loss: 0.115, Val loss: 0.117, Epoch time = 44.724s\n",
      "Epoch: 8, Train loss: 0.114, Val loss: 0.114, Epoch time = 44.711s\n",
      "Epoch: 9, Train loss: 0.112, Val loss: 0.112, Epoch time = 44.708s\n",
      "Epoch: 10, Train loss: 0.111, Val loss: 0.110, Epoch time = 44.755s\n",
      "Epoch: 11, Train loss: 0.109, Val loss: 0.109, Epoch time = 44.716s\n",
      "Epoch: 12, Train loss: 0.108, Val loss: 0.108, Epoch time = 44.706s\n",
      "Epoch: 13, Train loss: 0.107, Val loss: 0.107, Epoch time = 44.719s\n",
      "Epoch: 14, Train loss: 0.105, Val loss: 0.106, Epoch time = 44.717s\n",
      "Epoch: 15, Train loss: 0.104, Val loss: 0.105, Epoch time = 44.768s\n",
      "Epoch: 16, Train loss: 0.103, Val loss: 0.104, Epoch time = 44.702s\n",
      "Epoch: 17, Train loss: 0.102, Val loss: 0.103, Epoch time = 44.698s\n",
      "Epoch: 18, Train loss: 0.101, Val loss: 0.102, Epoch time = 44.700s\n",
      "Epoch: 19, Train loss: 0.100, Val loss: 0.102, Epoch time = 44.691s\n",
      "Epoch: 20, Train loss: 0.099, Val loss: 0.102, Epoch time = 44.691s\n",
      "Epoch: 21, Train loss: 0.099, Val loss: 0.101, Epoch time = 44.687s\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T21:49:08.137679Z",
     "start_time": "2024-07-21T21:49:08.120847Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), \"/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/model_1_notebook_v6.1.pth\")",
   "id": "c7d6c3fe415c9e19",
   "outputs": [],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
