{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Jetzt mit allen 88 Tasten",
   "id": "fc29e2e45b1f4be7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T20:12:21.922097Z",
     "start_time": "2024-07-08T20:12:20.924156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np"
   ],
   "id": "13798b388c091392",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T20:12:22.023403Z",
     "start_time": "2024-07-08T20:12:21.922852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if GPU is available, set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
   ],
   "id": "7454e3236bcc2b1a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T20:12:41.288055Z",
     "start_time": "2024-07-08T20:12:22.023952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from data_preperation import dataset_snapshot\n",
    "from transformer_decoder_training.dataprep_transformer import dataprep_1\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#load data\n",
    "dataset_as_snapshots = dataset_snapshot.process_dataset_multithreaded(\"/home/falaxdb/Repos/minus1/datasets/maestro_v3_split/hands_split_into_seperate_midis\", 0.05)\n",
    "# filter snapshots to 88 piano notes\n",
    "dataset_as_snapshots = dataset_snapshot.filter_piano_range(dataset_as_snapshots)\n",
    "\n",
    "\n"
   ],
   "id": "58248f46a2c1a1df",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed dataset (1038/1038): 100%|██████████| 1038/1038 [00:14<00:00, 73.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1038 of 1038 files\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T20:12:41.292014Z",
     "start_time": "2024-07-08T20:12:41.289064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split songs into train, test and val\n",
    "train_data, temp_data = train_test_split(dataset_as_snapshots, test_size=0.3, random_state=42, shuffle=True)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, shuffle=True)"
   ],
   "id": "f7575c3d58be65db",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T20:12:41.443181Z",
     "start_time": "2024-07-08T20:12:41.292415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define special Tokens\n",
    "# Token dimension needs to fit Data\n",
    "sos_token = np.full((1, 176), 1)\n",
    "pad_token = np.full((1, 176), 2)\n",
    "pad_token = torch.tensor(pad_token, device=device)\n",
    "\n",
    "# Define other parameters\n",
    "batch_size = 64\n",
    "seq_length = 512\n",
    "stride = 256"
   ],
   "id": "8ef4a706794d2797",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T20:12:48.870383Z",
     "start_time": "2024-07-08T20:12:41.443651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create dataset + dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer_decoder_training.dataset_transformer.dataset_2 import AdvancedPianoDataset\n",
    "\n",
    "train_dataset = AdvancedPianoDataset(train_data, seq_length, stride, sos_token)\n",
    "val_dataset = AdvancedPianoDataset(val_data, seq_length, stride, sos_token)\n",
    "test_dataset = AdvancedPianoDataset(test_data, seq_length, stride, sos_token)\n",
    "\n",
    "# Create DataLoaders for each subset with drop_last=True\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ],
   "id": "5ef6215e528aacb",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T20:12:48.882153Z",
     "start_time": "2024-07-08T20:12:48.875933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# initialize model\n",
    "\n",
    "# set parameters\n",
    "# Learning rate for the optimizer\n",
    "learning_rate = 1e-3\n",
    "# Number of epochs for training\n",
    "nepochs = 20\n",
    "\n",
    "# input size\n",
    "num_emb = 176\n",
    "# Embedding Size\n",
    "hidden_size = 256\n",
    "# Number of transformer blocks\n",
    "num_layers = 8\n",
    "# MultiheadAttention Heads\n",
    "num_heads = 8"
   ],
   "id": "15697849912a23f2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T20:12:49.560862Z",
     "start_time": "2024-07-08T20:12:48.883228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformer_decoder_training.models.transformer_decoder_1 import Transformer\n",
    "\n",
    "model = Transformer(num_emb=num_emb, num_layers=num_layers, hidden_size=hidden_size, num_heads=num_heads).to(device)\n",
    "\n",
    "# Initialize the optimizer with above parameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the loss function\n",
    "# loss function should be one that can handle multi one hot encoded vectors\n",
    "# Klammern nicht vergessen\n",
    "loss_fn = nn.BCELoss()"
   ],
   "id": "f28cea44aee555d9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "d5df3e8876ba8d1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T20:12:49.564784Z",
     "start_time": "2024-07-08T20:12:49.561410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_loop(model, opt, loss_fn, dataloader, pad_token, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        # Move data to GPU\n",
    "        src_sequence = batch.to(device)\n",
    "        \n",
    "        # create input and expected sequence -> move expected sequence one to the right\n",
    "        input_sequences = src_sequence[:, :-1]\n",
    "        expected_sequence = src_sequence[:, 1:]\n",
    "        \n",
    "        # Generate predictions\n",
    "        pred = model(input_sequences, pad_token)\n",
    "        \n",
    "        #print(\"Prediction shape:\", pred.shape)\n",
    "        #print(pred)\n",
    "        #print(\"expected harmony_shape:\", expected_harmony.shape)\n",
    "        #print(expected_harmony)\n",
    "        \n",
    "        # Calculate loss with masked cross-entropy\n",
    "        # ich glaube 0 steht in vorlage für padding token index -> habe ich hier anders\n",
    "        #mask = (expected_harmony != pad_token).float() Maske verwenden, um Padding positions im output zu canceln\n",
    "        # masked_pred = pred * mask\n",
    "        loss = loss_fn(pred, expected_sequence)\n",
    "        \n",
    "        # Backpropagation\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "        total_loss += loss.detach().item()\n",
    "        \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def validation_loop(model, loss_fn, dataloader,pad_token, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Move data to GPU\n",
    "            src_sequence = batch.to(device)\n",
    "            \n",
    "            # Create input and expected sequences\n",
    "            input_sequences = src_sequence[:, :-1, :]\n",
    "            expected_sequence = src_sequence[:, 1:, :]\n",
    "            \n",
    "            # Generate predictions\n",
    "            pred = model(input_sequences, pad_token)\n",
    "            \n",
    "            # Calculate loss without flattening\n",
    "            loss = loss_fn(pred, expected_sequence)\n",
    "            \n",
    "            total_loss += loss.detach().item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ],
   "id": "971413fa76bfa047",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T20:29:13.471278Z",
     "start_time": "2024-07-08T20:12:49.565521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 21\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_loop(model, optimizer, loss_fn, train_loader, pad_token, device)\n",
    "    end_time = timer()\n",
    "    val_loss = validation_loop(model, loss_fn, val_loader, pad_token, device)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
   ],
   "id": "dc5dd7ba698db70e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 0.061, Val loss: 0.044, Epoch time = 43.794s\n",
      "Epoch: 2, Train loss: 0.029, Val loss: 0.024, Epoch time = 43.577s\n",
      "Epoch: 3, Train loss: 0.023, Val loss: 0.022, Epoch time = 43.529s\n",
      "Epoch: 4, Train loss: 0.022, Val loss: 0.022, Epoch time = 43.496s\n",
      "Epoch: 5, Train loss: 0.021, Val loss: 0.021, Epoch time = 43.515s\n",
      "Epoch: 6, Train loss: 0.021, Val loss: 0.020, Epoch time = 43.473s\n",
      "Epoch: 7, Train loss: 0.021, Val loss: 0.020, Epoch time = 43.474s\n",
      "Epoch: 8, Train loss: 0.020, Val loss: 0.020, Epoch time = 43.493s\n",
      "Epoch: 9, Train loss: 0.020, Val loss: 0.020, Epoch time = 43.503s\n",
      "Epoch: 10, Train loss: 0.020, Val loss: 0.019, Epoch time = 43.481s\n",
      "Epoch: 11, Train loss: 0.020, Val loss: 0.019, Epoch time = 43.502s\n",
      "Epoch: 12, Train loss: 0.019, Val loss: 0.019, Epoch time = 43.455s\n",
      "Epoch: 13, Train loss: 0.019, Val loss: 0.019, Epoch time = 43.458s\n",
      "Epoch: 14, Train loss: 0.019, Val loss: 0.019, Epoch time = 43.489s\n",
      "Epoch: 15, Train loss: 0.019, Val loss: 0.019, Epoch time = 43.490s\n",
      "Epoch: 16, Train loss: 0.019, Val loss: 0.019, Epoch time = 43.560s\n",
      "Epoch: 17, Train loss: 0.018, Val loss: 0.018, Epoch time = 43.456s\n",
      "Epoch: 18, Train loss: 0.018, Val loss: 0.018, Epoch time = 43.457s\n",
      "Epoch: 19, Train loss: 0.018, Val loss: 0.018, Epoch time = 43.472s\n",
      "Epoch: 20, Train loss: 0.018, Val loss: 0.018, Epoch time = 43.495s\n",
      "Epoch: 21, Train loss: 0.018, Val loss: 0.018, Epoch time = 43.514s\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T20:29:13.516027Z",
     "start_time": "2024-07-08T20:29:13.471958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# see: https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html#save-and-load-the-model\n",
    "\n",
    "torch.save(model.state_dict(), \"/home/falaxdb/Repos/minus1/transformer_decoder_training/saved_files/saved_models/model_1_notebook_v7.pth\")"
   ],
   "id": "c0a81573f3802104",
   "outputs": [],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
